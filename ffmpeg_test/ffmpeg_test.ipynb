{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "from typing import Dict, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_every_n_images(images_path: Path, new_image_dir: Path, n: int = 2, offset: int = 0):\n",
    "    count = 0\n",
    "    new_image_dir.mkdir(exist_ok=True)\n",
    "    # Copy every n image from images_path to new_image_dir and rename it to be in the format %04d.png, the copy needs to be sorted by name\n",
    "    for image_path in sorted(images_path.glob(\"*.png\"))[offset::n]:\n",
    "        new_image_path = new_image_dir / f\"{count:04d}.png\"\n",
    "        subprocess.run([\"cp\", str(image_path), str(new_image_path)])\n",
    "        count += 1\n",
    "\n",
    "def copy_every_n_transforms(transforms_path: Path, new_transforms_path: Path, n: int = 2, offset: int = 0):\n",
    "    with open(transforms_path, \"r\") as f:\n",
    "        transforms = json.load(f)\n",
    "    \n",
    "    frames = transforms[\"frames\"]\n",
    "    new_frames = [frame for i, frame in enumerate(frames) if (i + offset) % n == 0]\n",
    "    new_transforms = copy.deepcopy(transforms)\n",
    "    new_transforms[\"frames\"] = new_frames\n",
    "\n",
    "    with open(new_transforms_path, \"w\") as f:\n",
    "        json.dump(new_transforms, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: Union[Path, str]):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FROM block_nerf/block_nerf.py\n",
    "\n",
    "def transform_camera_path(camera_path_path: Path, dataparser_transform_path: Path, export_path: Path = None):\n",
    "    \"\"\"\n",
    "    Transform a un-transformed camera path to a transformed camera path, in the respective transform's coordinate system.\n",
    "    \"\"\"\n",
    "    camera_path = load_json(camera_path_path)\n",
    "    dataparser_transform = load_json(dataparser_transform_path)\n",
    "\n",
    "    t = np.array(dataparser_transform[\"transform\"])\n",
    "    s = dataparser_transform[\"scale\"]\n",
    "\n",
    "    for i, camera in enumerate(camera_path[\"camera_path\"]):\n",
    "        c2w = np.array(camera[\"camera_to_world\"]).reshape(4, 4)\n",
    "        c2w = (t @ c2w) * s\n",
    "        c2w = np.vstack((c2w, np.array([0, 0, 0, 1])))\n",
    "        camera[\"camera_to_world\"] = c2w.reshape(16).tolist()\n",
    "\n",
    "    export_path = export_path if export_path is not None else camera_path_path.parent / \"camera_path_transformed.json\"\n",
    "    with open(export_path, \"w\") as f:\n",
    "        json.dump(camera_path, f, indent=4)\n",
    "\n",
    "    print(\"✅ Created transformed camera path at: \", export_path)\n",
    "    return export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_camera_path_from_transforms(transforms_path: Path, camera_path_path: Path, dataparser_transforms_path: Path, fps: int = 24):\n",
    "    with open(transforms_path, \"r\") as f:\n",
    "        transforms = json.load(f)\n",
    "    \n",
    "    frames = transforms[\"frames\"]\n",
    "    flattened_frames = [np.array(frame[\"transform_matrix\"]).flatten().tolist() for frame in frames]\n",
    "\n",
    "    new_camera_path = {\n",
    "        \"keyframes\": [],\n",
    "        \"camera_type\": \"perspective\",\n",
    "        \"render_height\": 1080,\n",
    "        \"render_width\": 1920,\n",
    "        \"camera_path\": [], # \"camera_to_world\"-dict with 16 double values in a 1D list.\n",
    "        \"fps\": fps,\n",
    "        \"seconds\": len(frames) / fps,\n",
    "        \"smoothness_value\": 0.46249999999999997,\n",
    "        \"is_cycle\": \"true\"\n",
    "    }\n",
    "\n",
    "    for c2w in flattened_frames:\n",
    "        new_camera_path[\"camera_path\"].append({\n",
    "            \"camera_to_world\": c2w,\n",
    "            \"fov\": 90,\n",
    "            \"aspect\": 1.6678200692041523 # TODO: Should I get this somewhere else?\n",
    "    })\n",
    "    \n",
    "    with open(camera_path_path, \"w\") as f:\n",
    "        json.dump(new_camera_path, f, indent=4)\n",
    "    \n",
    "    # Scale and translate the camera path to the trained NeRF's coordinate system.\n",
    "    # with open(dataparser_transforms_path, \"r\") as f:\n",
    "    #     dataparser_transforms = json.load(f)\n",
    "    \n",
    "    transform_camera_path(camera_path_path, dataparser_transforms_path, camera_path_path.parent / camera_path_path.name.replace(\".json\", \"_scaled.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images(images_path: Path, export_dir: Path, fps: int = 24):\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "    output_name = export_dir / f\"output-{get_timestamp()}.mp4\"\n",
    "    cmd = f\"ffmpeg -framerate {fps} -i {images_path}/%04d.png -c:v libx264 -r {fps} -pix_fmt yuv420p {output_name}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_path = Path(\"./transforms.json\")\n",
    "new_transforms_path = Path(\"./new_transforms.json\")\n",
    "images_path = Path(\"./images\")\n",
    "new_image_dir = Path(\"./new_images\")\n",
    "camera_path_path = Path(f\"camera_path-{get_timestamp()}.json\")\n",
    "dataparser_transforms_path = Path(\"./dataparser_transforms.json\")\n",
    "render_dir = Path(\"./renders\")\n",
    "\n",
    "# Right camera in a rig with 2 cameras\n",
    "n = 2\n",
    "offset = 1 \n",
    "fps = 24\n",
    "\n",
    "copy_every_n_transforms(transforms_path, new_transforms_path, n=n, offset=offset)\n",
    "copy_every_n_images(images_path, new_image_dir, n=n, offset=offset)\n",
    "create_video_from_images(new_image_dir, export_dir=render_dir, fps=fps)\n",
    "create_camera_path_from_transforms(transforms_path=new_transforms_path, camera_path_path=camera_path_path, dataparser_transforms_path=dataparser_transforms_path, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = Path(\"../data/images/side_by_side_test/0\")\n",
    "model_path = exp_path / \"side_by_side_test-0/nerfacto/2023-04-22_160821\"\n",
    "\n",
    "transforms_path = exp_path / \"transforms.json\"\n",
    "new_transforms_path = exp_path / \"new_transforms.json\"\n",
    "images_path = exp_path / \"images\"\n",
    "new_image_dir = exp_path / \"new_images\"\n",
    "camera_path_path = exp_path / f\"camera_path-{get_timestamp()}.json\"\n",
    "dataparser_transforms_path = model_path / \"dataparser_transforms.json\"\n",
    "render_dir = exp_path / \"renders\"\n",
    "\n",
    "# Right camera in a rig with 2 cameras\n",
    "n = 2\n",
    "offset = 1 \n",
    "fps = 24\n",
    "\n",
    "copy_every_n_transforms(transforms_path, new_transforms_path, n=n, offset=offset)\n",
    "copy_every_n_images(images_path, new_image_dir, n=n, offset=offset)\n",
    "create_video_from_images(new_image_dir, export_dir=render_dir, fps=fps)\n",
    "create_camera_path_from_transforms(transforms_path=new_transforms_path, camera_path_path=camera_path_path, dataparser_transforms_path=dataparser_transforms_path, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_side_by_side_video(video_paths: List[Path], export_path: Path):\n",
    "    # Rescale all input-videos to 1080p\n",
    "    rescaled_paths = []\n",
    "    for i, video_path in enumerate(video_paths):\n",
    "        rescaled_video_path = video_path.parent / f\"rescaled-{video_path.name}\"\n",
    "        cmd = f\"ffmpeg -n -i {video_path} -vf \\\"scale=w=960:h=540:force_original_aspect_ratio=1,pad=960:540:(ow-iw)/2:(oh-ih)/2\\\" -c:v libx264 {rescaled_video_path}\"\n",
    "        print(cmd)\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "        rescaled_paths.append(rescaled_video_path)\n",
    "    print(\"✅ Rescaled videos to 1080p\")\n",
    "\n",
    "    # Create side-by-side videoP\n",
    "    cmd = f\"ffmpeg -n {' '.join([f'-i {video_path}' for video_path in rescaled_paths])} -filter_complex hstack=inputs={len(rescaled_paths)} {export_path}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_render_path = Path(\"../data/images/side_by_side_test/0/renders/model_render.mp4\")\n",
    "input_render_path = Path(\"../data/images/side_by_side_test/0/renders/output-2023-04-22_16-20-16.mp4\")\n",
    "\n",
    "create_side_by_side_video([model_render_path, input_render_path], export_path=Path(\"../data/images/side_by_side_test/0/renders/side_by_side.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
