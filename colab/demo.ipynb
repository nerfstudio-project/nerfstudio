{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerfstudio-project/nerfstudio/blob/alex%2Fcolab310/colab/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiiXJ7K_fePG"
      },
      "source": [
        "<p align=\"center\">\n",
        "    <picture>\n",
        "    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.nerf.studio/en/latest/_images/logo-dark.png\">\n",
        "    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://docs.nerf.studio/en/latest/_images/logo.png\">\n",
        "    <img alt=\"nerfstudio\" src=\"https://docs.nerf.studio/en/latest/_images/logo.png\" width=\"400\">\n",
        "    </picture>\n",
        "</p>\n",
        "\n",
        "\n",
        "# Nerfstudio: A collaboration friendly studio for NeRFs\n",
        "\n",
        "\n",
        "![GitHub stars](https://img.shields.io/github/stars/nerfstudio-project/nerfstudio?color=gold&style=social)\n",
        "\n",
        "This colab shows how to train and view NeRFs from Nerfstudio both on pre-made datasets or from your own videos/images.\n",
        "\n",
        "\n",
        "\n",
        "Credit to [NeX](https://nex-mpi.github.io/) for Google Colab format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Frequently Asked Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyx5h6kz5ga7"
      },
      "source": [
        "*  **Downloading custom data is stalling (no output):**\n",
        "    * This is a bug in Colab. The data is processing, but may take a while to complete. You will know processing completed if `data/nerfstudio/custom_data/transforms.json` exists. Terminating the cell early will result in not being able to train.\n",
        "*  **Processing custom data is taking a long time:**\n",
        "    * The time it takes to process data depends on the number of images and its resolution. If processing is taking too long, try lowering the resolution of your custom data.\n",
        "*  **Error: Data processing did not complete:**\n",
        "    * This means that the data processing script did not fully complete. This could be because there were not enough images, or that the images were of low quality. We recommend images with little to no motion blur and lots of visual overlap of the scene to increase the chances of successful processing.\n",
        "*   **Training is not showing progress**:\n",
        "    * The lack of output is a bug in Colab. You can see the training progress from the viewer.\n",
        "* **Viewer Quality is bad / Low resolution**:\n",
        "    * This may be because more GPU is being used on training that rendering the viewer. Try pausing training or decreasing training utilization.\n",
        "* **WARNING: Running pip as the 'root' user...:**:\n",
        "    * This and other pip warnings or errors can be safely ignored.\n",
        "* **Other problems?**\n",
        "    * Feel free to create an issue on our [GitHub repo](https://github.com/nerfstudio-project/nerfstudio).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nerfstudio Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "9oyLHl8QfYwP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/'\n",
            "/home/gwu/nerfstudio/colab\n",
            "Requirement already satisfied: pip in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (23.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.0.1+cu118 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision==0.15.2+cu118 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (4.8.0)\n",
            "Requirement already satisfied: sympy in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (1.12)\n",
            "Requirement already satisfied: networkx in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torch==2.0.1+cu118) (2.0.0)\n",
            "Requirement already satisfied: numpy in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (1.26.0)\n",
            "Requirement already satisfied: requests in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (10.0.1)\n",
            "Requirement already satisfied: cmake in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.27.5)\n",
            "Requirement already satisfied: lit in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (17.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from jinja2->torch==2.0.1+cu118) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/gwu/miniconda3/envs/nerfstudio/lib/python3.10/site-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "[Errno 2] No such file or directory: '/content/'\n",
            "/home/gwu/nerfstudio/colab\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=1-7x7qQfB7bIw2zV4Lr6-yhvMpjXC84Q5&confirm=t\n",
            "To: /home/gwu/nerfstudio/colab/tinycudann-1.7-cp310-cp310-linux_x86_64.whl\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31.2M/31.2M [00:00<00:00, 50.7MB/s]\n",
            "Processing ./tinycudann-1.7-cp310-cp310-linux_x86_64.whl\n",
            "tinycudann is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "This module must ONLY run as part of a Colab notebook!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/nerfstudio/lib/python3.10/site-packages/condacolab.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/gwu/nerfstudio/colab/demo.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdecoder.eecs.berkeley.edu/home/gwu/nerfstudio/colab/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Installing COLMAP via conda\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdecoder.eecs.berkeley.edu/home/gwu/nerfstudio/colab/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q condacolab\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdecoder.eecs.berkeley.edu/home/gwu/nerfstudio/colab/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcondacolab\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdecoder.eecs.berkeley.edu/home/gwu/nerfstudio/colab/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m condacolab\u001b[39m.\u001b[39minstall()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdecoder.eecs.berkeley.edu/home/gwu/nerfstudio/colab/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mconda install -c conda-forge colmap\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/nerfstudio/lib/python3.10/site-packages/condacolab.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThis module must ONLY run as part of a Colab notebook!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.7\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m __author__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mJaime RodrÃ­guez-Guerra <jaimergp@users.noreply.github.com>\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This module must ONLY run as part of a Colab notebook!"
          ]
        }
      ],
      "source": [
        "#@markdown <h3>Install Nerfstudio and Dependencies (~8 min)</h3>\n",
        "\n",
        "%cd /content/\n",
        "!pip install --upgrade pip\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Installing TinyCuda\n",
        "%cd /content/\n",
        "!gdown \"https://drive.google.com/u/1/uc?id=1-7x7qQfB7bIw2zV4Lr6-yhvMpjXC84Q5&confirm=t\"\n",
        "!pip install tinycudann-1.7-cp310-cp310-linux_x86_64.whl\n",
        "\n",
        "# Installing COLMAP via conda\n",
        "%cd /content\n",
        "!conda install -c conda-forge colmap\n",
        "\n",
        "# Install nerfstudio\n",
        "%cd /content/\n",
        "!pip install git+https://github.com/nerfstudio-project/nerfstudio.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown <h3>Install COLMAP: Necessary for custom dataset (~15 min)</h3>\n",
        "#@markdown <medium>Skip to the next cell if running on demo data.<br/medium>\n",
        "#@markdown <medium>Run this cell if you are uploading your own data. Installation takes a while to complete.<br/medium>\n",
        "\n",
        "# Installing COLMAP via conda\n",
        "%cd /content\n",
        "!conda install -c conda-forge colmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "msVLprI4gRA4"
      },
      "outputs": [],
      "source": [
        "#@markdown <h3> Downloading and Processing Data</h3>\n",
        "#@markdown <medium>Pick the preset scene or upload your own images/video</medium>\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "scene = '\\uD83D\\uDDBC poster' #@param ['ğŸ–¼ poster', 'ğŸšœ dozer', 'ğŸŒ„ desolation', 'ğŸ“¤ upload your images' , 'ğŸ¥ upload your own video', 'ğŸ”º upload Polycam data', 'ğŸ’½ upload your own Record3D data']\n",
        "scene = ' '.join(scene.split(' ')[1:])\n",
        "\n",
        "if scene == \"upload Polycam data\":\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    if len(uploaded.keys()) > 1:\n",
        "        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n",
        "    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n",
        "    !ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene == 'upload your own Record3D data':\n",
        "    display(HTML('<h3>Zip your Record3D folder, and upload.</h3>'))\n",
        "    display(HTML('<h3>More information on Record3D can be found <a href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\">here</a>.</h3>'))\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    record_3d_zipfile = preupload_datasets[0]\n",
        "    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n",
        "    custom_data_directory = glob.glob('/content/data/nerfstudio/custom_data/*')[0]\n",
        "    !ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene in ['upload your images', 'upload your own video']:\n",
        "    display(HTML('<h3>Select your custom data</h3>'))\n",
        "    display(HTML('<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>'))\n",
        "    display(HTML('<p/>Note: This may take time, especially on higher resolution inputs, so we recommend to download dataset after creation.<p>'))\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    if scene == 'upload your images':\n",
        "        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n",
        "        %cd /content/data/nerfstudio/custom_data/raw_images\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    else:\n",
        "        %cd /content/data/nerfstudio/custom_data/\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    del uploaded\n",
        "    %cd /content/\n",
        "\n",
        "    if scene == 'upload your images':\n",
        "        !ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/\n",
        "    else:\n",
        "        video_path = preupload_datasets[0]\n",
        "        !ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/\n",
        "\n",
        "    scene = \"custom_data\"\n",
        "else:\n",
        "    %cd /content/\n",
        "    !ns-download-data nerfstudio --capture-name=$scene\n",
        "\n",
        "print(\"Data Processing Succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "VoKDxqEcjmfC",
        "outputId": "d2919aa4-96dd-4e50-829f-289e4208882b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors in 2.07s\n",
            "https://viewer.nerf.studio/?websocket_url=wss://cyan-facts-matter-34-91-1-218.loca.lt\n",
            "You may need to click Refresh Page after you start training!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"https://viewer.nerf.studio/?websocket_url=wss://cyan-facts-matter-34-91-1-218.loca.lt\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f1d0da6f950>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@markdown <h1>Set up and Start Viewer</h1>\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Install localtunnel\n",
        "# We are using localtunnel https://github.com/localtunnel/localtunnel but ngrok could also be used\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Tunnel port 7007, the default for\n",
        "!rm url.txt 2> /dev/null\n",
        "get_ipython().system_raw('lt --port 7007 >> url.txt 2>&1 &')\n",
        "\n",
        "import time\n",
        "time.sleep(3) # the previous command needs time to write to url.txt\n",
        "\n",
        "\n",
        "with open('url.txt') as f:\n",
        "  lines = f.readlines()\n",
        "websocket_url = lines[0].split(\": \")[1].strip().replace(\"https\", \"wss\")\n",
        "# from nerfstudio.utils.io import load_from_json\n",
        "# from pathlib import Path\n",
        "# json_filename = \"nerfstudio/nerfstudio/viewer/app/package.json\"\n",
        "# version = load_from_json(Path(json_filename))[\"version\"]\n",
        "url = f\"https://viewer.nerf.studio/?websocket_url={websocket_url}\"\n",
        "print(url)\n",
        "print(\"You may need to click Refresh Page after you start training!\")\n",
        "from IPython import display\n",
        "display.IFrame(src=url, height=800, width=\"100%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m_N8_cLfjoXD"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1>Start Training</h1>\n",
        "\n",
        "%cd /content\n",
        "if os.path.exists(f\"data/nerfstudio/{scene}/transforms.json\"):\n",
        "    !ns-train nerfacto --viewer.websocket-port 7007 --vis viewer_beta --viewer.make-share-url True nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4\n",
        "else:\n",
        "    from IPython.core.display import display, HTML\n",
        "    display(HTML('<h3 style=\"color:red\">Error: Data processing did not complete</h3>'))\n",
        "    display(HTML('<h3>Please re-run `Downloading and Processing Data`, or view the FAQ for more info.</h3>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGt8ukG6Htg3",
        "outputId": "fa946890-c7d8-4e46-a54e-7231bc5a2059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2;36m[19:48:48]\u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split train.                                          \u001b]8;id=527413;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243595;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split test.                                           \u001b]8;id=109270;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464675;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading latest checkpoint from load_dir\n",
            "âœ… Done loading checkpoint from \n",
            "outputs/data-nerfstudio-poster/nerfacto/\u001b[1;36m2022\u001b[0m-\u001b[1;36m10\u001b[0m-29_192844/nerfstudio_models/step-\u001b[1;36m000014000.\u001b[0mckpt\n",
            "\u001b[1;32mCreating trajectory video\u001b[0m\n",
            "\u001b[2KğŸ¥ Rendering ğŸ¥ \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[31m0.14 fps\u001b[0m \u001b[33m11:47\u001b[0m\n",
            "\u001b[2K\u001b[32m(  â—   )\u001b[0m \u001b[33mSaving video\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \u001b[0m\u001b[32m ğŸ‰ ğŸ‰ ğŸ‰ Success ğŸ‰ ğŸ‰ ğŸ‰\u001b[0m\u001b[92m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
            "                                           \u001b[32mSaved video to renders/output.mp4\u001b[0m                                            \n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title # Render Video { vertical-output: true }\n",
        "#@markdown <h3>Export the camera path from within the viewer, then run this cell.</h3>\n",
        "#@markdown <h5>The rendered video should be at renders/output.mp4!</h5>\n",
        "\n",
        "\n",
        "base_dir = \"/content/outputs/unnamed/nerfacto/\"\n",
        "training_run_dir = base_dir + os.listdir(base_dir)[0]\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<h3>Upload the camera path JSON.</h3>'))\n",
        "%cd $training_run_dir\n",
        "uploaded = files.upload()\n",
        "uploaded_camera_path_filename = list(uploaded.keys())[0]\n",
        "\n",
        "config_filename = training_run_dir + \"/config.yml\"\n",
        "camera_path_filename = training_run_dir + \"/\" + uploaded_camera_path_filename\n",
        "camera_path_filename = camera_path_filename.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n",
        "\n",
        "%cd /content/\n",
        "!ns-render camera-path --load-config $config_filename --camera-path-filename $camera_path_filename --output-path renders/output.mp4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('nerfstudio')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
