{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "class ABC:\n",
    "    a: int\n",
    "    b: int = 1\n",
    "    pass\n",
    "\n",
    "cls = ABC\n",
    "print (cls.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TestNestedClass' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ruilongli/workspace/pyrad/notebooks/test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 248>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=245'>246</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((\u001b[39m6\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=246'>247</a>\u001b[0m c \u001b[39m=\u001b[39m TestNestedClass(x\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mones(\u001b[39m6\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=247'>248</a>\u001b[0m tensor_dataclass \u001b[39m=\u001b[39m TestTensorDataclass(a\u001b[39m=\u001b[39;49ma, b\u001b[39m=\u001b[39;49mb, c\u001b[39m=\u001b[39;49mc)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=248'>249</a>\u001b[0m \u001b[39mprint\u001b[39m (is_tensordataclass(tensor_dataclass))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=249'>250</a>\u001b[0m \u001b[39mprint\u001b[39m (is_tensordataclass(tensor_dataclass\u001b[39m.\u001b[39mc))\n",
      "\u001b[1;32m/home/ruilongli/workspace/pyrad/notebooks/test.ipynb Cell 2\u001b[0m in \u001b[0;36mtensordataclass.<locals>.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=52'>53</a>\u001b[0m     \u001b[39massert\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(value, FIELD_TYPES[i]), (\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=53'>54</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__init__() got a wrong type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m v.s. \u001b[39m\u001b[39m{\u001b[39;00mFIELD_TYPES[i]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=54'>55</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m for argument `\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=55'>56</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=56'>57</a>\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, key, value)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=58'>59</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__post_init__()\n",
      "\u001b[1;32m/home/ruilongli/workspace/pyrad/notebooks/test.ipynb Cell 2\u001b[0m in \u001b[0;36mtensordataclass.<locals>.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=70'>71</a>\u001b[0m             batch_shapes\u001b[39m.\u001b[39mappend(v\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=71'>72</a>\u001b[0m         \u001b[39melif\u001b[39;00m is_tensordataclass(v):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=72'>73</a>\u001b[0m             batch_shapes\u001b[39m.\u001b[39mappend(v\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch_shapes) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000011vscode-remote?line=74'>75</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTensorDataclass must have at least one tensor\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TestNestedClass' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union\n",
    "from torchtyping import TensorType\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "_IDENTIFER = \"__tensordataclass__\"\n",
    "\n",
    "def is_tensordataclass(x):\n",
    "    return hasattr(x.__class__, _IDENTIFER)   \n",
    "\n",
    "def tensordataclass(cls):\n",
    "\n",
    "    FIELD_KEYS = list(cls.__annotations__.keys())\n",
    "    FIELD_TYPES = list(cls.__annotations__.values())\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        # Quietly pop out and save these arguments from kwargs.\n",
    "        self._shape: Tuple[int] = kwargs.pop(\"_shape\", None)\n",
    "        self._packed_info: TensorType[\"num_chunks\", 3] = kwargs.pop(\"_packed_info\", None)\n",
    "\n",
    "        # check the remaining arguments\n",
    "        n_params = len(args) + len(kwargs.values())\n",
    "        n_params_max = len(FIELD_KEYS)\n",
    "        assert n_params <= n_params_max, (\n",
    "            f\"__init__() takes from 1 to {n_params_max + 1} positional arguments\"\n",
    "            f\" but {n_params + 1} were given\"\n",
    "        )\n",
    "\n",
    "        # collect attributes\n",
    "        init_params = {}\n",
    "        for i, value in enumerate(args):\n",
    "            key = FIELD_KEYS[i]\n",
    "            init_params.update({key: value})\n",
    "        for key, value in kwargs.items():\n",
    "            assert key not in init_params, (\n",
    "                f\"__init__() got multiple values for argument '{key}'\"\n",
    "            )\n",
    "            assert key in FIELD_KEYS, (\n",
    "                f\"__init__() got an unexpected keyword argument '{key}'\"\n",
    "            )\n",
    "            init_params.update({key: value})\n",
    "        for key in FIELD_KEYS:\n",
    "            if key in init_params:\n",
    "                continue\n",
    "            assert hasattr(self, key), (\n",
    "                f\"__init__() missing 1 required positional argument: '{key}'\"\n",
    "            )\n",
    "            value = getattr(self, key)\n",
    "            init_params.update({key: value})\n",
    "\n",
    "        # set attributes\n",
    "        for i, (key, value) in enumerate(init_params.items()):\n",
    "            assert value is None or isinstance(value, FIELD_TYPES[i]), (\n",
    "                f\"__init__() got a wrong type {type(value)} v.s. {FIELD_TYPES[i]}\"\n",
    "                f\" for argument `{key}`\"\n",
    "            )\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        self.__post_init__()\n",
    "        \n",
    "    def __post_init__(self) -> None:\n",
    "        if self.is_packed():\n",
    "            # Do nothing for a packed tensor\n",
    "            return\n",
    "        \n",
    "        batch_shapes = []\n",
    "        for f in FIELD_KEYS:\n",
    "            v = self.__getattribute__(f)\n",
    "            if v is not None:\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    batch_shapes.append(v.shape[:-1])\n",
    "                elif is_tensordataclass(v):\n",
    "                    batch_shapes.append(v.shape)\n",
    "        if len(batch_shapes) == 0:\n",
    "            raise ValueError(\"TensorDataclass must have at least one tensor\")\n",
    "        batch_shape = torch.broadcast_shapes(*batch_shapes)\n",
    "\n",
    "        for f in FIELD_KEYS:\n",
    "            v = self.__getattribute__(f)\n",
    "            if v is not None:\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    self.__setattr__(f, v.broadcast_to((*batch_shape, v.shape[-1])))\n",
    "                elif is_tensordataclass(v):\n",
    "                    self.__setattr__(f, v.broadcast_to(batch_shape))\n",
    "\n",
    "        self._shape = batch_shape\n",
    "\n",
    "    def __getitem__(self, indices) -> cls:\n",
    "        if self.is_packed():\n",
    "            raise IndexError(\"Packed TensorDataClass can not be indexed!\")\n",
    "        if isinstance(indices, torch.Tensor):\n",
    "            return self._apply_fn_to_fields(lambda x: x[indices])\n",
    "        if isinstance(indices, (int, slice)):\n",
    "            indices = (indices,)\n",
    "        tensor_fn = lambda x: x[indices + (slice(None),)]\n",
    "        dataclass_fn = lambda x: x[indices]\n",
    "        return self._apply_fn_to_fields(tensor_fn, dataclass_fn)\n",
    "\n",
    "    def __setitem__(self, indices, value) -> cls:\n",
    "        raise RuntimeError(\"Index assignment is not supported for TensorDataclass\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.shape[0]\n",
    "\n",
    "    def __bool__(self) -> bool:\n",
    "        if len(self) == 0:\n",
    "            raise ValueError(\n",
    "                f\"The truth value of {self.__class__.__name__} when `len(x) == 0` \"\n",
    "                \"is ambiguous. Use `len(x)` or `x is not None`.\"\n",
    "            )\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> tuple:\n",
    "        \"\"\"Returns the batch shape of the tensor dataclass.\"\"\"\n",
    "        if self._shape is None:\n",
    "            raise RuntimeError(\"Packed TensorDataClass does not have a shape defined!\")\n",
    "        else:\n",
    "            return self._shape\n",
    "    \n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Returns the number of elements in the tensor dataclass batch dimension.\"\"\"\n",
    "        if len(self.shape) == 0:\n",
    "            return 1\n",
    "        return int(np.prod(self.shape))\n",
    "\n",
    "    @property\n",
    "    def ndim(self) -> int:\n",
    "        \"\"\"Returns the number of dimensions of the tensor dataclass.\"\"\"\n",
    "        return len(self.shape)\n",
    "\n",
    "    def reshape(self, shape: Tuple[int, ...]) -> cls:\n",
    "        \"\"\"Returns a new TensorDataclass with the same data but with a new shape.\n",
    "\n",
    "        Args:\n",
    "            shape (Tuple[int]): The new shape of the tensor dataclass.\n",
    "\n",
    "        Returns:\n",
    "            TensorDataclass: A new TensorDataclass with the same data but with a new shape.\n",
    "        \"\"\"\n",
    "        if self.is_packed():\n",
    "            raise RuntimeError(\"Packed TensorDataclass can not be reshaped!\")\n",
    "        if isinstance(shape, int):\n",
    "            shape = (shape,)\n",
    "        tensor_fn = lambda x: x.reshape((*shape, x.shape[-1]))\n",
    "        dataclass_fn = lambda x: x.reshape(shape)\n",
    "        return self._apply_fn_to_fields(tensor_fn, dataclass_fn)\n",
    "\n",
    "    def flatten(self) -> cls:\n",
    "        \"\"\"Returns a new TensorDataclass with flattened batch dimensions\n",
    "\n",
    "        Returns:\n",
    "            TensorDataclass: A new TensorDataclass with the same data but with a new shape.\n",
    "        \"\"\"\n",
    "        if self.is_packed():\n",
    "            raise RuntimeError(\"Packed TensorDataclass can not be flatten!\")\n",
    "        return self.reshape((-1,))\n",
    "\n",
    "    def broadcast_to(self, shape: Union[torch.Size, Tuple[int]]) -> \"TensorDataclass\":\n",
    "        \"\"\"Returns a new TensorDataclass broadcast to new shape.\n",
    "\n",
    "        Args:\n",
    "            shape (Tuple[int]): The new shape of the tensor dataclass.\n",
    "\n",
    "        Returns:\n",
    "            TensorDataclass: A new TensorDataclass with the same data but with a new shape.\n",
    "        \"\"\"\n",
    "        if self.is_packed():\n",
    "            raise RuntimeError(\"Packed TensorDataclass can not be broadcasted!\")\n",
    "        return self._apply_fn_to_fields(lambda x: x.broadcast_to((*shape, x.shape[-1])))\n",
    "\n",
    "    def to(self, device) -> cls:\n",
    "        \"\"\"Returns a new TensorDataclass with the same data but on the specified device.\n",
    "\n",
    "        Args:\n",
    "            device: The device to place the tensor dataclass.\n",
    "\n",
    "        Returns:\n",
    "            TensorDataclass: A new TensorDataclass with the same data but on the specified device.\n",
    "        \"\"\"\n",
    "        return self._apply_fn_to_fields(lambda x: x.to(device))\n",
    "\n",
    "    def _apply_fn_to_fields(\n",
    "        self,\n",
    "        fn: callable,\n",
    "        dataclass_fn: callable = None,\n",
    "        exclude_fields: List[str] = None,\n",
    "        **kwargs,\n",
    "    ) -> cls:\n",
    "        \"\"\"Applies a function to all fields of the tensor dataclass.\n",
    "\n",
    "        Args:\n",
    "            fn (callable): The function to apply to tensor fields.\n",
    "            dataclass_fn (callable): The function to apply to TensorDataclass fields. Else use fn.\n",
    "            exclude_fields (List[str]): The fields to be excluded from calling fn and dataclass_fn.\n",
    "            **kwargs: Additional arguments to initialize the new TensorDataclass.\n",
    "\n",
    "        Returns:\n",
    "            cls: A new class with the same data but with a new shape.\n",
    "        \"\"\"\n",
    "        if exclude_fields is None:\n",
    "            exclude_fields = []\n",
    "\n",
    "        field_names = [f for f in FIELD_KEYS if f not in exclude_fields]\n",
    "        new_fields = {}\n",
    "        for f in field_names:\n",
    "            v = self.__getattribute__(f)\n",
    "            if v is not None:\n",
    "                if is_tensordataclass(v) and dataclass_fn is not None:\n",
    "                    new_fields[f] = dataclass_fn(v)\n",
    "                elif isinstance(v, torch.Tensor) or is_tensordataclass(v):\n",
    "                    new_fields[f] = fn(v)\n",
    "        new_fields.update(kwargs)\n",
    "\n",
    "        return cls(**new_fields)\n",
    "\n",
    "    def is_packed(self) -> bool:\n",
    "        \"\"\"Returns whether the data are packed.\"\"\"\n",
    "        return self._packed_info is not None\n",
    "\n",
    "    setattr(cls, _IDENTIFER, {})\n",
    "    setattr(cls, \"__init__\", __init__)\n",
    "    setattr(cls, \"__post_init__\", __post_init__)\n",
    "    setattr(cls, \"__getitem__\", __getitem__)\n",
    "    setattr(cls, \"__setitem__\", __setitem__)\n",
    "    setattr(cls, \"__len__\", __len__)\n",
    "    setattr(cls, \"__bool__\", __bool__)\n",
    "    setattr(cls, \"shape\", shape)\n",
    "    setattr(cls, \"size\", size)\n",
    "    setattr(cls, \"ndim\", ndim)\n",
    "    setattr(cls, \"reshape\", reshape)\n",
    "    setattr(cls, \"flatten\", flatten)\n",
    "    setattr(cls, \"broadcast_to\", broadcast_to)\n",
    "    setattr(cls, \"to\", to)\n",
    "    setattr(cls, \"_apply_fn_to_fields\", _apply_fn_to_fields)\n",
    "    setattr(cls, \"is_packed\", is_packed)\n",
    "    return cls\n",
    "\n",
    "@tensordataclass\n",
    "class TestNestedClass():\n",
    "    \"\"\"Dummy dataclass\"\"\"\n",
    "\n",
    "    x: torch.Tensor\n",
    "\n",
    "\n",
    "@tensordataclass\n",
    "class TestTensorDataclass():\n",
    "    \"\"\"Dummy dataclass\"\"\"\n",
    "\n",
    "    a: torch.Tensor\n",
    "    b: torch.Tensor\n",
    "    c: TestNestedClass = None\n",
    "\n",
    "a = torch.ones((4, 6, 3))\n",
    "b = torch.ones((6, 2))\n",
    "c = TestNestedClass(x=torch.ones(6, 5))\n",
    "tensor_dataclass = TestTensorDataclass(a=a, b=b, c=c)\n",
    "print (is_tensordataclass(tensor_dataclass))\n",
    "print (is_tensordataclass(tensor_dataclass.c))\n",
    "out = tensor_dataclass.to(\"cuda:0\")\n",
    "print (out.a.device)\n",
    "print (out.c.x.device)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <class 'int'>, 'b': <class 'int'>}\n"
     ]
    }
   ],
   "source": [
    "print (cls.__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (getattr(cls, \"a\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _MISSING_TYPE:\n",
    "    pass\n",
    "\n",
    "\n",
    "MISSING = _MISSING_TYPE()\n",
    "\n",
    "# pyline: disable=redefined-builtin\n",
    "def _create_fn(name, args, body, *, globals=None, locals=None, return_type=MISSING):\n",
    "    # Note that we mutate locals when exec() is called.  Caller\n",
    "    # beware!  The only callers are internal to this module, so no\n",
    "    # worries about external callers.\n",
    "    if locals is None:\n",
    "        locals = {}\n",
    "    return_annotation = \"\"\n",
    "    if return_type is not MISSING:\n",
    "        locals[\"_return_type\"] = return_type\n",
    "        return_annotation = \"->_return_type\"\n",
    "    args = \",\".join(args)\n",
    "    body = \"\\n\".join(f\"  {b}\" for b in body)\n",
    "\n",
    "    # Compute the text of the entire function.\n",
    "    txt = f\" def {name}({args}){return_annotation}:\\n{body}\"\n",
    "\n",
    "    local_vars = \", \".join(locals.keys())\n",
    "    txt = f\"def __create_fn__({local_vars}):\\n{txt}\\n return {name}\"\n",
    "\n",
    "    ns = {}\n",
    "    exec(txt, globals, ns)  # pyline: disable=exec-used\n",
    "    return ns[\"__create_fn__\"](**locals)\n",
    "\n",
    "locals = {[name, type, ] for name, type in cls.__annotations__.items()}\n",
    "\n",
    "getattr(cls, \"a\", None)\n",
    "\n",
    "_create_fn('__init__',\n",
    "                    [self_name] + [_init_param(f) for f in fields if f.init],\n",
    "                    body_lines,\n",
    "                    locals=locals,\n",
    "                    globals=globals,\n",
    "                    return_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__create_fn__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ruilongli/workspace/pyrad/notebooks/test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbirman/home/ruilongli/workspace/pyrad/notebooks/test.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m __create_fn__\n",
      "\u001b[0;31mNameError\u001b[0m: name '__create_fn__' is not defined"
     ]
    }
   ],
   "source": [
    "__create_fn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tensordataclass(cls):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        \n",
    "\n",
    "    run = getattr(cls, 'run')\n",
    "    def new_run(self):\n",
    "        print('before')\n",
    "        run(self)\n",
    "        print('after')\n",
    "    setattr(cls, 'run', new_run)\n",
    "    return cls\n",
    "\n",
    "\n",
    "class Task(object): pass\n",
    "\n",
    "@decorate_run\n",
    "class MyTask(Task):\n",
    "    def run(self):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyrad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1930976eb75c9ad2b420ba44a38e7193e5ac8873ec603a7c6ff958f682deb115"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
