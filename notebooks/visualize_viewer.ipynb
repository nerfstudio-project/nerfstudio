{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c00934d-0f14-4c1a-a563-94d627b377e5",
   "metadata": {},
   "source": [
    "## Notebook to visualize the viewer functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15dfdc1-5054-40bc-9631-4c7426eecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_imports import *\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pyrad.data.dataloader import TrainDataloader\n",
    "from pyrad.data.image_dataset import ImageDataset, PanopticImageDataset\n",
    "from pyrad.data.image_sampler import CacheImageSampler\n",
    "from pyrad.data.pixel_sampler import PixelSampler\n",
    "from pyrad.data.utils import DatasetInputs, get_dataset_inputs_from_dataset_config\n",
    "from pyrad.graphs.modules.ray_generator import RayGenerator\n",
    "from pyrad.graphs.modules.scene_colliders import SceneBoundsCollider, AABBBoxCollider\n",
    "from pyrad.cameras.cameras import get_camera\n",
    "from pyrad.cameras.camera_paths import InterpolatedCameraPath\n",
    "from pyrad.cameras.rays import RayBundle\n",
    "from pyrad.utils.io import get_absolute_path\n",
    "from pyrad.utils.plotly import get_line_segments_from_lines\n",
    "from pyrad.cameras.cameras import get_camera_model\n",
    "from pyrad.utils.misc import get_dict_to_torch, instantiate_from_dict_config\n",
    "\n",
    "# the new import\n",
    "from pyrad.viewer.backend import vis_utils\n",
    "\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import open_dict\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032e4c9e-25be-4cc0-9ac8-a5be723b775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the connection to the tcp backend, to talk to the visualizer\n",
    "# zmq_url should match the output of `python run_zmq_server.py`\n",
    "vis = vis_utils.get_vis(zmq_url=\"tcp://127.0.0.1:6000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df82e083-e261-43e0-a1dc-05c6a59d16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.delete()\n",
    "\n",
    "# draws a red box in the scene\n",
    "vis_utils.show_box_test(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c0c266-668a-4522-b573-f5f0626b0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vis[\"/Cameras/Main Camera\"].get_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c404cbd9-b759-4b84-909f-e4a5bce42d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x83\\xa4type\\xaaset_object\\xa4path\\xb3Cameras/Main Camera\\xa6object\\x82\\xa8metadata\\x83\\xa7version\\xcb@\\x12\\x00\\x00\\x00\\x00\\x00\\x00\\xa4type\\xa6Object\\xa9generator\\xafObject3D.toJSON\\xa6object\\x8c\\xa4uuid\\xd9$9a332925-1e54-436a-a6d5-56dc185a39ba\\xa4type\\xb1PerspectiveCamera\\xa6layers\\x01\\xa6matrix\\xdc\\x00\\x10\\xcb?\\xe6\\xa0\\x9ef\\x7f;\\xcc\\xcb\\xbc\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\xcb?\\xe6\\xa0\\x9ef\\x7f;\\xcc\\x00\\xcb\\xbf\\xda \\xbdp\\x0c,<\\xcb\\xbf\\xea \\xbdp\\x0c,<\\xcb?\\xda \\xbdp\\x0c,=\\x00\\xcb?\\xe2y\\xa7E\\x903\\x1c\\xcb\\xbf\\xe2y\\xa7E\\x903\\x1c\\xcb\\xbf\\xe2y\\xa7E\\x903\\x1a\\x00\\x05\\xfb\\xfb\\x01\\xa3fovx\\xa4zoom\\x01\\xa4near\\xcb?\\x84z\\xe1G\\xae\\x14{\\xa3fard\\xa5focus\\n\\xa6aspect\\xcb?\\xf6\\x9df8\\x15\\xb5\\xd3\\xa9filmGauge#\\xaafilmOffset\\x00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a730b0f4-2c61-4df1-b325-d2dd1cc7f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umsgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e28700a-2e04-4de1-947b-aad0dfacc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = umsgpack.unpackb(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674fb793-d37b-440f-8647-a2abcbf8aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrad.viewer.backend.utils import get_chunks, get_intrinsics_matrix_and_camera_to_world_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab76869-3632-4c2a-bf07-72c139e399e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_object = m[\"object\"][\"object\"]\n",
    "intrinsics_matrix, camera_to_world_h = get_intrinsics_matrix_and_camera_to_world_h(camera_object, image_height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf2a229-4a38-4837-b19f-c45557fd61c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.86751346,  0.        , 70.67137809],\n",
       "       [ 0.        , 28.86751346, 50.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsics_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec787baa-ad43-4953-a724-6347c6d700bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.07106781e-01, -4.08248290e-01,  5.77350269e-01,\n",
       "         5.00000000e+00],\n",
       "       [-2.77555756e-17, -8.16496581e-01, -5.77350269e-01,\n",
       "        -5.00000000e+00],\n",
       "       [ 7.07106781e-01,  4.08248290e-01, -5.77350269e-01,\n",
       "        -5.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_to_world_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e190e-2949-4a00-bda3-f1dc20725374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506dd712-6aaa-43bd-bc9e-e77d78e7b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.random.rand(100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99a1d88-85b9-4117-85ef-7985a9593965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a41499-c0a2-4b49-a54d-1822bd84b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ok'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis[\"/Cameras/Main Camera\"].set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e89319-97ec-400b-8c81-bee169d8eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ee435fc-f8db-42b7-9e35-e50d2c651bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_to_world_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7044462-3e34-48d6-81b5-6eca5b558866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "729514df-ebcc-4887-8663-53ddff983a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4134275618374559"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "499f17b8-3e11-422e-bafc-cc2a729476e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(camera_to_world_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b354ee2-8670-4826-9e56-ceaa80c2e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'version': 4.5,\n",
       "  'type': 'Object',\n",
       "  'generator': 'Object3D.toJSON'},\n",
       " 'object': {'uuid': '8b429d04-9f7f-4461-b1bb-9bdd5ff6748c',\n",
       "  'type': 'PerspectiveCamera',\n",
       "  'castShadow': True,\n",
       "  'receiveShadow': True,\n",
       "  'layers': 1,\n",
       "  'matrix': [0.5620843398756875,\n",
       "   -0.31160318996883307,\n",
       "   -0.7661361803672765,\n",
       "   0,\n",
       "   -0.3924307317037816,\n",
       "   0.7149266753901418,\n",
       "   -0.5786864173540215,\n",
       "   0,\n",
       "   0.7280517259652277,\n",
       "   0.6259259547397327,\n",
       "   0.27956642055548614,\n",
       "   0,\n",
       "   6.305112899549926,\n",
       "   5.420677776926363,\n",
       "   2.421116222461348,\n",
       "   1],\n",
       "  'fov': 120,\n",
       "  'zoom': 1,\n",
       "  'near': 0.01,\n",
       "  'far': 100,\n",
       "  'focus': 10,\n",
       "  'aspect': 1.4134275618374559,\n",
       "  'filmGauge': 35,\n",
       "  'filmOffset': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe7478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    config = compose(config_name=\"graph_default.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642b0a25-0e88-4eac-b661-a57a74fb10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inputs = get_dataset_inputs_from_dataset_config(**config.data.dataset_inputs_train, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938f090b-3b28-4fd6-82dc-d4b5c5917134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataset\n",
    "image_dataset_train = instantiate_from_dict_config(config.data.image_dataset_train, **dataset_inputs.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d014a6b-50fa-48ab-b135-0ab2b81c7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab 10 images and show their frustums\n",
    "indices = random.sample(range(len(image_dataset_train)), k=10)\n",
    "for idx in indices:\n",
    "    image = image_dataset_train[idx][\"image\"]\n",
    "    camera = get_camera(dataset_inputs.intrinsics[idx], dataset_inputs.camera_to_world[idx], None)\n",
    "    pose = camera.get_camera_to_world().double().numpy()\n",
    "    K = camera.get_intrinsics_matrix().double().numpy()\n",
    "    vis_utils.draw_camera_frustum(\n",
    "        vis,\n",
    "        image=(image.double().numpy() * 255.0),\n",
    "        pose=pose,\n",
    "        K=K,\n",
    "        height=1.0,\n",
    "        name=\"{:06d}\".format(idx),\n",
    "        displayed_focal_length=0.5,\n",
    "        realistic=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd04703a-aa50-45e4-95fd-4d881ff18d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated_time: 3.3333333333333335\n",
      "time_elapsed: 3.54646897315979\n"
     ]
    }
   ],
   "source": [
    "# move a camera around\n",
    "num_cameras = len(dataset_inputs.intrinsics)\n",
    "intrinsics = dataset_inputs.intrinsics\n",
    "camera_to_world = dataset_inputs.camera_to_world\n",
    "idx0, idx1 = random.sample(range(num_cameras), k=2)\n",
    "camera_a = get_camera(intrinsics[idx0], camera_to_world[idx0], None)\n",
    "camera_b = get_camera(intrinsics[idx1], camera_to_world[idx1], None)\n",
    "\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "estimated_time = num_steps / fps\n",
    "print(\"estimated_time:\", estimated_time)\n",
    "\n",
    "camera_path = InterpolatedCameraPath(camera_a, camera_b)\n",
    "cameras = camera_path.get_path(steps=num_steps)\n",
    "\n",
    "start = time.time()\n",
    "for camera in cameras:\n",
    "    vis_utils.set_camera(vis, camera)\n",
    "    time.sleep(1 / fps)\n",
    "time_elapsed = time.time() - start\n",
    "print(\"time_elapsed:\", time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd7183-c514-4f87-a8cc-e14228228e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a749acc7d255f078aee52e0584cc77b3cb5aaed1b3a7407ec4262c1bf6cb526"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
