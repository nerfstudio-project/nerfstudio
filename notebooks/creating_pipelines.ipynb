{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipelines\n",
    "\n",
    "Here we explain how to create custom pipelines in nerfactory. Pipelines are composed of two components, namely a Dataloader and a Model. We'll show how to make an incremental dataloader with scene conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "import torch\n",
    "\n",
    "from nerfactory.dataloaders.base import Dataloader\n",
    "from nerfactory.models.base import Model\n",
    "from nerfactory.pipelines.base import Pipeline\n",
    "\n",
    "from nerfactory.models.instant_ngp import NGPModel\n",
    "from nerfactory.cameras.rays import RayBundle\n",
    "\n",
    "\n",
    "class IncrementalDataloader(Dataloader):\n",
    "    \"\"\"A SLAM-based dataloader.\"\"\"\n",
    "\n",
    "    def populate_train_modules(self):\n",
    "        \"\"\"Populate the train dataloader modules.\"\"\"\n",
    "        # self.train_image_dataset = ImageDataset\n",
    "        # self.train_image_sampler = CacheImageSampler\n",
    "        # self.train_pixel_sampler = PixelSampler\n",
    "        # self.train_ray_generator = RayGenerator\n",
    "\n",
    "    def populate_eval_modules(self):\n",
    "        \"\"\"Populate the eval dataloader modules.\"\"\"\n",
    "        # self.eval_image_dataset = ImageDataset\n",
    "        # self.eval_dataloader = FixedIndicesEvalDataloader\n",
    "\n",
    "    def next_train(self, step: int):\n",
    "        \"\"\"Get the next batch of training data by stringing together the train modules.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def next_eval(self, step: int):\n",
    "        \"\"\"Get the next batch of eval data by stringing together the eval modules.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class SceneConditionNGPModel(Model):\n",
    "    \"\"\"An instant ngp model modified slightly to output semantics.\"\"\"\n",
    "\n",
    "    def populate_modules(self):\n",
    "        self.ngp_model = NGPModel()\n",
    "\n",
    "    def get_outputs(self, ray_bundle: RayBundle, batch: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]:\n",
    "        # TODO(ethan): pass in batch from the forward function\n",
    "        # TODO(ethan): rename batch to something else\n",
    "        outputs = self.ngp_model.forward(ray_bundle)\n",
    "        outputs[\"semantics\"] = torch.rand_like(outputs[\"rgb\"])\n",
    "        return outputs\n",
    "\n",
    "    def get_loss_dict(self):\n",
    "        return {}\n",
    "\n",
    "\n",
    "class CustomPipeline(Pipeline):\n",
    "    \"\"\"The Instant NGP pipeline.\"\"\"\n",
    "\n",
    "    # NOTE(ethan): what does this do in Python?\n",
    "    dataloader: IncrementalDataloader\n",
    "    model: SceneConditionNGPModel\n",
    "    # viewer: Viewer # TODO(ethan): do we want the viewer logic inside the pipeline? not sure?\n",
    "\n",
    "    def next_train(self, step: int):\n",
    "        ray_bundle, batch = self.dataloader.next_train(step=step)\n",
    "        # TODO: maybe run a CNN on the data before passing into model\n",
    "        model_outputs, loss_dict, metrics_dict = self.model(ray_bundle, batch)\n",
    "        return model_outputs, loss_dict, metrics_dict\n",
    "\n",
    "    def next_eval(self):\n",
    "        raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(use_train=True, use_eval=True)\n",
    "model = SemanticNGPModel()\n",
    "pipeline = CustomPipeline(dataloader=dataloader, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipelines from a config\n",
    "\n",
    "Now we show how to create a pipeline from a config, which has the following form:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Configuration for pipeline instantiation\"\"\"\n",
    "\n",
    "    _target_: str = MISSING\n",
    "    dataloader_config: DataloaderConfig = MISSING\n",
    "    graph_config: GraphConfig = MISSING\n",
    "```\n",
    "\n",
    "See [nerfactory/utils/config.py](nerfactory/utils/config.py) for more details. In this example, we will simply load from an existing configuration from [configs/graph_instant_ngp.yaml](configs/graph_instant_ngp.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import hydra\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "from hydra import compose, initialize\n",
    "\n",
    "initialize(version_base=\"1.2\", config_path=\"../configs/\")\n",
    "config_name = \"graph_instant_ngp.yaml\"\n",
    "config = compose(config_name)\n",
    "pipeline_config = config.pipeline\n",
    "pprint.pprint(pipeline_config)\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "from nerfactory.pipelines.base import setup_pipeline\n",
    "\n",
    "pipeline = setup_pipeline(pipeline_config, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_train_loss_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nerfactory')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e691f033e0f2f1b9c0a11e7e81375a1e27aec87a71fd1b1eaa545f7a5e61b3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
