#compdef ns-train

# AUTOMATICALLY GENERATED by `shtab`


_shtab_tyro_ns_train_commands() {
  local _commands=(
    "depth-nerfacto:Nerfacto with depth supervision."
    "dnerf:Dynamic-NeRF model. (slow)"
    "instant-ngp:Implementation of Instant-NGP. Recommended real-time model for unbounded scenes."
    "instant-ngp-bounded:Implementation of Instant-NGP. Recommended for bounded real and synthetic scenes"
    "lerf:Base config for LERF"
    "lerf-big:A larger version of LERF with a higher memory footprint, bigger CLIP model, and more hashgrid capacity"
    "lerf-lite:A lightweight version of LERF designed to work on smaller GPUs"
    "mipnerf:High quality model for bounded scenes. (slow)"
    "nerfacto:Recommended real-time model tuned for real captures. This model will be continually updated."
    "nerfacto-big:"
    "nerfplayer-nerfacto:NeRFPlayer with nerfacto backbone."
    "nerfplayer-ngp:NeRFPlayer with InstantNGP backbone."
    "neus:Implementation of NeuS. (slow)"
    "neus-facto:"
    "phototourism:Uses the Phototourism data."
    "semantic-nerfw:Predicts semantic segmentations and filters out transient objects."
    "tensorf:tensorf"
    "vanilla-nerf:Original NeRF model. (slow)"
    "volinga:Real-time rendering model from Volinga. Directly exportable to NVOL format at https\:\/\/volinga.ai\/"
  )
  _describe 'ns-train commands' _commands
}

_shtab_tyro_ns_train_depth_nerfacto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train depth-nerfacto commands' _commands
}

_shtab_tyro_ns_train_dnerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train dnerf commands' _commands
}

_shtab_tyro_ns_train_instant_ngp_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train instant-ngp commands' _commands
}

_shtab_tyro_ns_train_instant_ngp_bounded_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train instant-ngp-bounded commands' _commands
}

_shtab_tyro_ns_train_lerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train lerf commands' _commands
}

_shtab_tyro_ns_train_lerf_big_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train lerf-big commands' _commands
}

_shtab_tyro_ns_train_lerf_lite_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train lerf-lite commands' _commands
}

_shtab_tyro_ns_train_mipnerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train mipnerf commands' _commands
}

_shtab_tyro_ns_train_nerfacto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfacto commands' _commands
}

_shtab_tyro_ns_train_nerfacto_big_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfacto-big commands' _commands
}

_shtab_tyro_ns_train_nerfplayer_nerfacto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfplayer-nerfacto commands' _commands
}

_shtab_tyro_ns_train_nerfplayer_ngp_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfplayer-ngp commands' _commands
}

_shtab_tyro_ns_train_neus_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train neus commands' _commands
}

_shtab_tyro_ns_train_neus_facto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train neus-facto commands' _commands
}

_shtab_tyro_ns_train_phototourism_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train phototourism commands' _commands
}

_shtab_tyro_ns_train_semantic_nerfw_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train semantic-nerfw commands' _commands
}

_shtab_tyro_ns_train_tensorf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train tensorf commands' _commands
}

_shtab_tyro_ns_train_vanilla_nerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train vanilla-nerf commands' _commands
}

_shtab_tyro_ns_train_volinga_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train volinga commands' _commands
}

_shtab_tyro_ns_train_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_depth_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: depth-nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.depth-loss-mult[Lambda of the depth loss. (default\: 0.001)]:pipeline.model.depth-loss-mult:"
  "--pipeline.model.is-euclidean-depth[Whether input depth maps are Euclidean distances (or z-distances). (default\: False)]:pipeline.model.is-euclidean-depth:(True False)"
  "--pipeline.model.depth-sigma[Uncertainty around depth values in meters (defaults to 1cm). (default\: 0.01)]:pipeline.model.depth-sigma:"
  "--pipeline.model.should-decay-sigma[Whether to exponentially decay sigma. (default\: False)]:pipeline.model.should-decay-sigma:(True False)"
  "--pipeline.model.starting-depth-sigma[Starting uncertainty around depth values in meters (defaults to 0.2m). (default\: 0.2)]:pipeline.model.starting-depth-sigma:"
  "--pipeline.model.sigma-decay-rate[Rate of exponential decay. (default\: 0.99985)]:pipeline.model.sigma-decay-rate:"
  "--pipeline.model.depth-loss-type[Depth loss type. (default\: DS_NERF)]:pipeline.model.depth-loss-type:(DS_NERF URF)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_depth_nerfacto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_depth_nerfacto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_depth_nerfacto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_depth_nerfacto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_depth_nerfacto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_dnerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: dnerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 64)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: True)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--optimizers.temporal-distortion.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.temporal-distortion.optimizer.lr:"
  "--optimizers.temporal-distortion.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.temporal-distortion.optimizer.eps:"
  "--optimizers.temporal-distortion.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.temporal-distortion.optimizer.max-norm:"
  "--optimizers.temporal-distortion.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.temporal-distortion.optimizer.weight-decay:"
  "--optimizers.temporal-distortion.scheduler[(default\: None)]:optimizers.temporal-distortion.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_dnerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_dnerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_dnerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_dnerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_dnerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_dnerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_dnerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_dnerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_dnerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_dnerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_instant_ngp_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: instant-ngp)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 64000)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 8192)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: False)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[Instant NGP doesn\'t use a collider. (default\: None)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 8192)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.max-num-samples-per-ray[Number of samples in field evaluation. (default\: 24)]:pipeline.model.max-num-samples-per-ray:"
  "--pipeline.model.grid-resolution[Resolution of the grid used for the field. (default\: 128)]:pipeline.model.grid-resolution:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.contraction-type[Contraction type used for spatial deformation of the field. (default\: UN_BOUNDED_SPHERE)]:pipeline.model.contraction-type:(AABB UN_BOUNDED_TANH UN_BOUNDED_SPHERE)"
  "--pipeline.model.cone-angle[Should be set to 0.0 for blender scenes but 1.\/256 for real scenes. (default\: 0.004)]:pipeline.model.cone-angle:"
  "--pipeline.model.render-step-size[Minimum step size for rendering. (default\: 0.01)]:pipeline.model.render-step-size:"
  "--pipeline.model.near-plane[How far along ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.use-appearance-embedding[Whether to use an appearance embedding. (default\: False)]:pipeline.model.use-appearance-embedding:(True False)"
  "--pipeline.model.background-color[The color that is given to untrained areas. (default\: random)]:pipeline.model.background-color:(random black white)"
  "--pipeline.target-num-samples[The target number of samples to use for an entire batch of rays. (default\: 262144)]:pipeline.target-num-samples:"
  "--pipeline.max-num-samples-per-ray[The maximum number of samples to be placed along a ray. (default\: 1024)]:pipeline.max-num-samples-per-ray:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: instant-ngp-bounded)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 64000)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 8192)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: False)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[Instant NGP doesn\'t use a collider. (default\: None)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 8192)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.max-num-samples-per-ray[Number of samples in field evaluation. (default\: 48)]:pipeline.model.max-num-samples-per-ray:"
  "--pipeline.model.grid-resolution[Resolution of the grid used for the field. (default\: 128)]:pipeline.model.grid-resolution:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.contraction-type[Contraction type used for spatial deformation of the field. (default\: AABB)]:pipeline.model.contraction-type:(AABB UN_BOUNDED_TANH UN_BOUNDED_SPHERE)"
  "--pipeline.model.cone-angle[Should be set to 0.0 for blender scenes but 1.\/256 for real scenes. (default\: 0.004)]:pipeline.model.cone-angle:"
  "--pipeline.model.render-step-size[Minimum step size for rendering. (default\: 0.001)]:pipeline.model.render-step-size:"
  "--pipeline.model.near-plane[How far along ray to start sampling. (default\: 0.01)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.use-appearance-embedding[Whether to use an appearance embedding. (default\: False)]:pipeline.model.use-appearance-embedding:(True False)"
  "--pipeline.model.background-color[The color that is given to untrained areas. (default\: black)]:pipeline.model.background-color:(random black white)"
  "--pipeline.target-num-samples[The target number of samples to use for an entire batch of rays. (default\: 262144)]:pipeline.target-num-samples:"
  "--pipeline.max-num-samples-per-ray[The maximum number of samples to be placed along a ray. (default\: 1024)]:pipeline.max-num-samples-per-ray:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_instant_ngp_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_instant_ngp_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_instant_ngp_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_instant_ngp_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.patch-tile-size-range[(default\: 0.05 0.5)]:pipeline.datamanager.patch-tile-size-range:"
  "--pipeline.datamanager.patch-tile-size-res[(default\: 7)]:pipeline.datamanager.patch-tile-size-res:"
  "--pipeline.datamanager.patch-stride-scaler[(default\: 0.5)]:pipeline.datamanager.patch-stride-scaler:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.clip-loss-weight[(default\: 0.1)]:pipeline.model.clip-loss-weight:"
  "--pipeline.model.n-scales[(default\: 30)]:pipeline.model.n-scales:"
  "--pipeline.model.max-scale[maximum scale used to compute relevancy with (default\: 1.5)]:pipeline.model.max-scale:"
  "--pipeline.model.num-lerf-samples[(default\: 24)]:pipeline.model.num-lerf-samples:"
  "--pipeline.model.hashgrid-layers[(default\: 12 12)]:pipeline.model.hashgrid-layers:"
  "--pipeline.model.hashgrid-resolutions[(default\: 16 128 128 512)]:pipeline.model.hashgrid-resolutions:"
  "--pipeline.model.hashgrid-sizes[(default\: 19 19)]:pipeline.model.hashgrid-sizes:"
  "--pipeline.network.clip-model-type[(default\: ViT-B-16)]:pipeline.network.clip-model-type:"
  "--pipeline.network.clip-model-pretrained[(default\: laion2b_s34b_b88k)]:pipeline.network.clip-model-pretrained:"
  "--pipeline.network.clip-n-dims[(default\: 512)]:pipeline.network.clip-n-dims:"
  "--pipeline.network.negatives[(default\: object things stuff texture)]:pipeline.network.negatives:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--optimizers.lerf.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.lerf.optimizer.lr:"
  "--optimizers.lerf.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.lerf.optimizer.eps:"
  "--optimizers.lerf.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.lerf.optimizer.max-norm:"
  "--optimizers.lerf.optimizer.weight-decay[The weight decay to use. (default\: 1e-09)]:optimizers.lerf.optimizer.weight-decay:"
  "--optimizers.lerf.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.lerf.scheduler.lr-pre-warmup:"
  "--optimizers.lerf.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.lerf.scheduler.lr-final:"
  "--optimizers.lerf.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.lerf.scheduler.warmup-steps:"
  "--optimizers.lerf.scheduler.max-steps[The maximum number of steps. (default\: 4000)]:optimizers.lerf.scheduler.max-steps:"
  "--optimizers.lerf.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.lerf.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_lerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_big_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf-big)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.patch-tile-size-range[(default\: 0.05 0.5)]:pipeline.datamanager.patch-tile-size-range:"
  "--pipeline.datamanager.patch-tile-size-res[(default\: 7)]:pipeline.datamanager.patch-tile-size-res:"
  "--pipeline.datamanager.patch-stride-scaler[(default\: 0.5)]:pipeline.datamanager.patch-stride-scaler:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.clip-loss-weight[(default\: 0.1)]:pipeline.model.clip-loss-weight:"
  "--pipeline.model.n-scales[(default\: 30)]:pipeline.model.n-scales:"
  "--pipeline.model.max-scale[maximum scale used to compute relevancy with (default\: 1.5)]:pipeline.model.max-scale:"
  "--pipeline.model.num-lerf-samples[(default\: 32)]:pipeline.model.num-lerf-samples:"
  "--pipeline.model.hashgrid-layers[(default\: 16 16)]:pipeline.model.hashgrid-layers:"
  "--pipeline.model.hashgrid-resolutions[(default\: 16 128 128 512)]:pipeline.model.hashgrid-resolutions:"
  "--pipeline.model.hashgrid-sizes[(default\: 19 19)]:pipeline.model.hashgrid-sizes:"
  "--pipeline.network.clip-model-type[(default\: ViT-L-14)]:pipeline.network.clip-model-type:"
  "--pipeline.network.clip-model-pretrained[(default\: laion2b_s32b_b82k)]:pipeline.network.clip-model-pretrained:"
  "--pipeline.network.clip-n-dims[(default\: 768)]:pipeline.network.clip-n-dims:"
  "--pipeline.network.negatives[(default\: object things stuff texture)]:pipeline.network.negatives:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--optimizers.lerf.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.lerf.optimizer.lr:"
  "--optimizers.lerf.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.lerf.optimizer.eps:"
  "--optimizers.lerf.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.lerf.optimizer.max-norm:"
  "--optimizers.lerf.optimizer.weight-decay[The weight decay to use. (default\: 1e-09)]:optimizers.lerf.optimizer.weight-decay:"
  "--optimizers.lerf.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.lerf.scheduler.lr-pre-warmup:"
  "--optimizers.lerf.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.lerf.scheduler.lr-final:"
  "--optimizers.lerf.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.lerf.scheduler.warmup-steps:"
  "--optimizers.lerf.scheduler.max-steps[The maximum number of steps. (default\: 3000)]:optimizers.lerf.scheduler.max-steps:"
  "--optimizers.lerf.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.lerf.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_lerf_big_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_big_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_big_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_big_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_lerf_big_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_big_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_lerf_big_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_big_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.99)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_big_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_lerf_big_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_big_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_big_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_lerf_big_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_lerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_lite_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf-lite)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.patch-tile-size-range[(default\: 0.05 0.5)]:pipeline.datamanager.patch-tile-size-range:"
  "--pipeline.datamanager.patch-tile-size-res[(default\: 7)]:pipeline.datamanager.patch-tile-size-res:"
  "--pipeline.datamanager.patch-stride-scaler[(default\: 0.5)]:pipeline.datamanager.patch-stride-scaler:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.clip-loss-weight[(default\: 0.1)]:pipeline.model.clip-loss-weight:"
  "--pipeline.model.n-scales[(default\: 30)]:pipeline.model.n-scales:"
  "--pipeline.model.max-scale[maximum scale used to compute relevancy with (default\: 1.5)]:pipeline.model.max-scale:"
  "--pipeline.model.num-lerf-samples[(default\: 12)]:pipeline.model.num-lerf-samples:"
  "--pipeline.model.hashgrid-layers[(default\: 16)]:pipeline.model.hashgrid-layers:"
  "--pipeline.model.hashgrid-resolutions[(default\: 16 512)]:pipeline.model.hashgrid-resolutions:"
  "--pipeline.model.hashgrid-sizes[(default\: 19)]:pipeline.model.hashgrid-sizes:"
  "--pipeline.network.clip-model-type[(default\: ViT-B-16)]:pipeline.network.clip-model-type:"
  "--pipeline.network.clip-model-pretrained[(default\: laion2b_s34b_b88k)]:pipeline.network.clip-model-pretrained:"
  "--pipeline.network.clip-n-dims[(default\: 512)]:pipeline.network.clip-n-dims:"
  "--pipeline.network.negatives[(default\: object things stuff texture)]:pipeline.network.negatives:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--optimizers.lerf.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.lerf.optimizer.lr:"
  "--optimizers.lerf.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.lerf.optimizer.eps:"
  "--optimizers.lerf.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.lerf.optimizer.max-norm:"
  "--optimizers.lerf.optimizer.weight-decay[The weight decay to use. (default\: 1e-09)]:optimizers.lerf.optimizer.weight-decay:"
  "--optimizers.lerf.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.lerf.scheduler.lr-pre-warmup:"
  "--optimizers.lerf.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.001)]:optimizers.lerf.scheduler.lr-final:"
  "--optimizers.lerf.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.lerf.scheduler.warmup-steps:"
  "--optimizers.lerf.scheduler.max-steps[The maximum number of steps. (default\: 7000)]:optimizers.lerf.scheduler.max-steps:"
  "--optimizers.lerf.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.lerf.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_lerf_lite_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_lite_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_lite_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_lerf_lite_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_lerf_lite_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_lite_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_lerf_lite_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_lite_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.99)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_lite_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_lerf_lite_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_lite_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_lite_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_lerf_lite_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_lerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_lerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.99)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_lerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_lerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_lerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_lerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_mipnerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: mipnerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 0.1)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 1024)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 128)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: False)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_mipnerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_mipnerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_mipnerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_mipnerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_mipnerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_mipnerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_mipnerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_mipnerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_mipnerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_mipnerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 6e-06)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.proposal-networks.scheduler.lr-pre-warmup:"
  "--optimizers.proposal-networks.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.proposal-networks.scheduler.lr-final:"
  "--optimizers.proposal-networks.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.proposal-networks.scheduler.warmup-steps:"
  "--optimizers.proposal-networks.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.proposal-networks.scheduler.max-steps:"
  "--optimizers.proposal-networks.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.proposal-networks.scheduler.ramp:(linear cosine)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_nerfacto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.001)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 128)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 128)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 128)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 3000)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 21)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 512 256)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 128)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 5000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 100000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 100000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_big_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_big_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfacto_big_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_big_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfacto_big_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfacto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfacto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfacto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfacto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfplayer-nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (Random is reported to be better on DyCheck.) (default\: random)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Hashing grid parameter. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Hashing grid parameter. (default\: 18)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.temporal-dim[(default\: 32)]:pipeline.model.proposal-net-args-list.0.temporal-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 64)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.temporal-dim[(default\: 32)]:pipeline.model.proposal-net-args-list.1.temporal-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.01)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.features-per-level[Hashing grid parameter. (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.temporal-dim[Hashing grid parameter. A higher temporal dim means a higher temporal frequency. (default\: 32)]:pipeline.model.temporal-dim:"
  "--pipeline.model.temporal-tv-weight[Temporal TV balancing weight for feature channels. (default\: 1)]:pipeline.model.temporal-tv-weight:"
  "--pipeline.model.depth-weight[depth loss balancing weight for feature channels. (default\: 0.1)]:pipeline.model.depth-weight:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfplayer-ngp)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 64000)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 8192)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: False)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[Instant NGP doesn\'t use a collider. (default\: None)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 8192)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.max-num-samples-per-ray[Number of samples in field evaluation. (default\: 48)]:pipeline.model.max-num-samples-per-ray:"
  "--pipeline.model.grid-resolution[Resolution of the grid used for the field. (default\: 128)]:pipeline.model.grid-resolution:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Hashing grid parameter. (default\: 17)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.contraction-type[Contraction type used for spatial deformation of the field. (default\: AABB)]:pipeline.model.contraction-type:(AABB UN_BOUNDED_TANH UN_BOUNDED_SPHERE)"
  "--pipeline.model.cone-angle[Should be set to 0.0 for blender scenes but 1.\/256 for real scenes. (default\: 0.004)]:pipeline.model.cone-angle:"
  "--pipeline.model.render-step-size[Minimum step size for rendering. (default\: 0.001)]:pipeline.model.render-step-size:"
  "--pipeline.model.near-plane[How far along ray to start sampling. (default\: 0.01)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.use-appearance-embedding[Whether to use an appearance embedding. (default\: False)]:pipeline.model.use-appearance-embedding:(True False)"
  "--pipeline.model.background-color[The color that is given to untrained areas. (default\: random)]:pipeline.model.background-color:(random black white)"
  "--pipeline.model.temporal-dim[Hashing grid parameter. A higher temporal dim means a higher temporal frequency. (default\: 64)]:pipeline.model.temporal-dim:"
  "--pipeline.model.num-levels[Hashing grid parameter. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.features-per-level[Hashing grid parameter. (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.base-resolution[Hashing grid parameter. (default\: 16)]:pipeline.model.base-resolution:"
  "--pipeline.model.temporal-tv-weight[Temporal TV loss balancing weight for feature channels. (default\: 1)]:pipeline.model.temporal-tv-weight:"
  "--pipeline.model.depth-weight[depth loss balancing weight for feature channels. (default\: 0.1)]:pipeline.model.depth-weight:"
  "--pipeline.model.train-background-color[The training background color that is given to untrained areas. (default\: random)]:pipeline.model.train-background-color:(random black white)"
  "--pipeline.model.eval-background-color[The training background color that is given to untrained areas. (default\: white)]:pipeline.model.eval-background-color:(random black white)"
  "--pipeline.model.disable-viewing-dependent[Disable viewing dependent effects. (default\: True)]:pipeline.model.disable-viewing-dependent:(True False)"
  "--pipeline.target-num-samples[The target number of samples to use for an entire batch of rays. (default\: 262144)]:pipeline.target-num-samples:"
  "--pipeline.max-num-samples-per-ray[The maximum number of samples to be placed along a ray. (default\: 1024)]:pipeline.max-num-samples-per-ray:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfplayer_ngp_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_neus_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: neus)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 1024)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 4.0)]:pipeline.model.far-plane:"
  "--pipeline.model.far-plane-bg[How far along the ray to stop sampling of the background model. (default\: 1000.0)]:pipeline.model.far-plane-bg:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: black)]:pipeline.model.background-color:(random last_sample white black)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: False)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.eikonal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.1)]:pipeline.model.eikonal-loss-mult:"
  "--pipeline.model.fg-mask-loss-mult[Foreground mask loss multiplier. (default\: 0.01)]:pipeline.model.fg-mask-loss-mult:"
  "--pipeline.model.mono-normal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-normal-loss-mult:"
  "--pipeline.model.mono-depth-loss-mult[Monocular depth consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-depth-loss-mult:"
  "--pipeline.model.sdf-field.num-layers[Number of layers for geometric network (default\: 8)]:pipeline.model.sdf-field.num-layers:"
  "--pipeline.model.sdf-field.hidden-dim[Number of hidden dimension of geometric network (default\: 256)]:pipeline.model.sdf-field.hidden-dim:"
  "--pipeline.model.sdf-field.geo-feat-dim[Dimension of geometric feature (default\: 256)]:pipeline.model.sdf-field.geo-feat-dim:"
  "--pipeline.model.sdf-field.num-layers-color[Number of layers for color network (default\: 4)]:pipeline.model.sdf-field.num-layers-color:"
  "--pipeline.model.sdf-field.hidden-dim-color[Number of hidden dimension of color network (default\: 256)]:pipeline.model.sdf-field.hidden-dim-color:"
  "--pipeline.model.sdf-field.appearance-embedding-dim[Dimension of appearance embedding (default\: 32)]:pipeline.model.sdf-field.appearance-embedding-dim:"
  "--pipeline.model.sdf-field.use-appearance-embedding[Dimension of appearance embedding (default\: False)]:pipeline.model.sdf-field.use-appearance-embedding:(True False)"
  "--pipeline.model.sdf-field.bias[sphere size of geometric initializaion (default\: 0.8)]:pipeline.model.sdf-field.bias:"
  "--pipeline.model.sdf-field.geometric-init[Whether to use geometric initialization (default\: True)]:pipeline.model.sdf-field.geometric-init:(True False)"
  "--pipeline.model.sdf-field.inside-outside[whether to revert signed distance value, set to True for indoor scene (default\: True)]:pipeline.model.sdf-field.inside-outside:(True False)"
  "--pipeline.model.sdf-field.weight-norm[Whether to use weight norm for linear layer (default\: True)]:pipeline.model.sdf-field.weight-norm:(True False)"
  "--pipeline.model.sdf-field.use-grid-feature[Whether to use multi-resolution feature grids (default\: False)]:pipeline.model.sdf-field.use-grid-feature:(True False)"
  "--pipeline.model.sdf-field.divide-factor[Normalization factor for multi-resolution grids (default\: 2.0)]:pipeline.model.sdf-field.divide-factor:"
  "--pipeline.model.sdf-field.beta-init[Init learnable beta value for transformation of sdf to density (default\: 0.1)]:pipeline.model.sdf-field.beta-init:"
  "--pipeline.model.sdf-field.encoding-type[(default\: hash)]:pipeline.model.sdf-field.encoding-type:(hash periodic tensorf_vm)"
  "--pipeline.model.background-model[background models (default\: mlp)]:pipeline.model.background-model:(grid mlp none)"
  "--pipeline.model.num-samples-outside[Number of samples outside the bounding sphere for backgound (default\: 32)]:pipeline.model.num-samples-outside:"
  "--pipeline.model.periodic-tvl-mult[Total variational loss mutliplier (default\: 0.0)]:pipeline.model.periodic-tvl-mult:"
  "--pipeline.model.overwrite-near-far-plane[whether to use near and far collider from command line (default\: False)]:pipeline.model.overwrite-near-far-plane:(True False)"
  "--pipeline.model.num-samples[Number of uniform samples (default\: 64)]:pipeline.model.num-samples:"
  "--pipeline.model.num-samples-importance[Number of importance samples (default\: 64)]:pipeline.model.num-samples-importance:"
  "--pipeline.model.num-up-sample-steps[number of up sample step, 1 for simple coarse-to-fine sampling (default\: 4)]:pipeline.model.num-up-sample-steps:"
  "--pipeline.model.base-variance[fixed base variance in NeuS sampler, the inv_s will be base \* 2 \*\* iter during upsample (default\: 64)]:pipeline.model.base-variance:"
  "--pipeline.model.perturb[use to use perturb for the sampled points (default\: True)]:pipeline.model.perturb:(True False)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.warm-up-end[Iteration number where warmp ends (default\: 5000)]:optimizers.fields.scheduler.warm-up-end:"
  "--optimizers.fields.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.fields.scheduler.learning-rate-alpha:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 300000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.field-background.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.field-background.optimizer.lr:"
  "--optimizers.field-background.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.field-background.optimizer.eps:"
  "--optimizers.field-background.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.field-background.optimizer.max-norm:"
  "--optimizers.field-background.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.field-background.optimizer.weight-decay:"
  "--optimizers.field-background.scheduler.warm-up-end[Iteration number where warmp ends (default\: 5000)]:optimizers.field-background.scheduler.warm-up-end:"
  "--optimizers.field-background.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.field-background.scheduler.learning-rate-alpha:"
  "--optimizers.field-background.scheduler.max-steps[The maximum number of steps. (default\: 300000)]:optimizers.field-background.scheduler.max-steps:"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 20000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 5000)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 1000000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 100000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_neus_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_neus_facto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: neus-facto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 2048)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 2048)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 2048)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 4.0)]:pipeline.model.far-plane:"
  "--pipeline.model.far-plane-bg[How far along the ray to stop sampling of the background model. (default\: 1000.0)]:pipeline.model.far-plane-bg:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: black)]:pipeline.model.background-color:(random last_sample white black)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: False)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.eikonal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.1)]:pipeline.model.eikonal-loss-mult:"
  "--pipeline.model.fg-mask-loss-mult[Foreground mask loss multiplier. (default\: 0.01)]:pipeline.model.fg-mask-loss-mult:"
  "--pipeline.model.mono-normal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-normal-loss-mult:"
  "--pipeline.model.mono-depth-loss-mult[Monocular depth consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-depth-loss-mult:"
  "--pipeline.model.sdf-field.num-layers[Number of layers for geometric network (default\: 2)]:pipeline.model.sdf-field.num-layers:"
  "--pipeline.model.sdf-field.hidden-dim[Number of hidden dimension of geometric network (default\: 256)]:pipeline.model.sdf-field.hidden-dim:"
  "--pipeline.model.sdf-field.geo-feat-dim[Dimension of geometric feature (default\: 256)]:pipeline.model.sdf-field.geo-feat-dim:"
  "--pipeline.model.sdf-field.num-layers-color[Number of layers for color network (default\: 2)]:pipeline.model.sdf-field.num-layers-color:"
  "--pipeline.model.sdf-field.hidden-dim-color[Number of hidden dimension of color network (default\: 256)]:pipeline.model.sdf-field.hidden-dim-color:"
  "--pipeline.model.sdf-field.appearance-embedding-dim[Dimension of appearance embedding (default\: 32)]:pipeline.model.sdf-field.appearance-embedding-dim:"
  "--pipeline.model.sdf-field.use-appearance-embedding[Dimension of appearance embedding (default\: False)]:pipeline.model.sdf-field.use-appearance-embedding:(True False)"
  "--pipeline.model.sdf-field.bias[sphere size of geometric initializaion (default\: 0.5)]:pipeline.model.sdf-field.bias:"
  "--pipeline.model.sdf-field.geometric-init[Whether to use geometric initialization (default\: True)]:pipeline.model.sdf-field.geometric-init:(True False)"
  "--pipeline.model.sdf-field.inside-outside[whether to revert signed distance value, set to True for indoor scene (default\: True)]:pipeline.model.sdf-field.inside-outside:(True False)"
  "--pipeline.model.sdf-field.weight-norm[Whether to use weight norm for linear layer (default\: True)]:pipeline.model.sdf-field.weight-norm:(True False)"
  "--pipeline.model.sdf-field.use-grid-feature[Whether to use multi-resolution feature grids (default\: True)]:pipeline.model.sdf-field.use-grid-feature:(True False)"
  "--pipeline.model.sdf-field.divide-factor[Normalization factor for multi-resolution grids (default\: 2.0)]:pipeline.model.sdf-field.divide-factor:"
  "--pipeline.model.sdf-field.beta-init[Init learnable beta value for transformation of sdf to density (default\: 0.8)]:pipeline.model.sdf-field.beta-init:"
  "--pipeline.model.sdf-field.encoding-type[(default\: hash)]:pipeline.model.sdf-field.encoding-type:(hash periodic tensorf_vm)"
  "--pipeline.model.background-model[background models (default\: none)]:pipeline.model.background-model:(grid mlp none)"
  "--pipeline.model.num-samples-outside[Number of samples outside the bounding sphere for backgound (default\: 32)]:pipeline.model.num-samples-outside:"
  "--pipeline.model.periodic-tvl-mult[Total variational loss mutliplier (default\: 0.0)]:pipeline.model.periodic-tvl-mult:"
  "--pipeline.model.overwrite-near-far-plane[whether to use near and far collider from command line (default\: False)]:pipeline.model.overwrite-near-far-plane:(True False)"
  "--pipeline.model.num-samples[Number of uniform samples (default\: 64)]:pipeline.model.num-samples:"
  "--pipeline.model.num-samples-importance[Number of importance samples (default\: 64)]:pipeline.model.num-samples-importance:"
  "--pipeline.model.num-up-sample-steps[number of up sample step, 1 for simple coarse-to-fine sampling (default\: 4)]:pipeline.model.num-up-sample-steps:"
  "--pipeline.model.base-variance[fixed base variance in NeuS sampler, the inv_s will be base \* 2 \*\* iter during upsample (default\: 64)]:pipeline.model.base-variance:"
  "--pipeline.model.perturb[use to use perturb for the sampled points (default\: True)]:pipeline.model.perturb:(True False)"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for the proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-neus-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-neus-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 64)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.proposal-networks.scheduler.max-steps:"
  "--optimizers.proposal-networks.scheduler.gamma[The learning rate decay factor. (default\: 0.33)]:optimizers.proposal-networks.scheduler.gamma:"
  "--optimizers.proposal-networks.scheduler.milestones[The milestone steps at which to decay the learning rate. (default\: 10000 1500 18000)]:optimizers.proposal-networks.scheduler.milestones:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.warm-up-end[Iteration number where warmp ends (default\: 500)]:optimizers.fields.scheduler.warm-up-end:"
  "--optimizers.fields.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.fields.scheduler.learning-rate-alpha:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.field-background.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.field-background.optimizer.lr:"
  "--optimizers.field-background.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.field-background.optimizer.eps:"
  "--optimizers.field-background.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.field-background.optimizer.max-norm:"
  "--optimizers.field-background.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.field-background.optimizer.weight-decay:"
  "--optimizers.field-background.scheduler.warm-up-end[Iteration number where warmp ends (default\: 500)]:optimizers.field-background.scheduler.warm-up-end:"
  "--optimizers.field-background.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.field-background.scheduler.learning-rate-alpha:"
  "--optimizers.field-background.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.field-background.scheduler.max-steps:"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 5000)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 5000)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 1000000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 20001)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_neus_facto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_facto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_facto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_neus_facto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_neus_facto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_neus_facto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_facto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_neus_facto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_facto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_neus_facto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_neus_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_neus_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_neus_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_neus_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_neus_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_phototourism_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: phototourism)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: 40)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: 100)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: 40)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: 100)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_phototourism_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_phototourism_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_phototourism_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_phototourism_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_phototourism_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_phototourism_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_phototourism_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_phototourism_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_phototourism_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_phototourism_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_semantic_nerfw_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: semantic-nerfw)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 65536)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 8192)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 65536)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-transient-embedding[Whether to use transient embedding. (default\: False)]:pipeline.model.use-transient-embedding:(True False)"
  "--pipeline.model.semantic-loss-weight[(default\: 1.0)]:pipeline.model.semantic-loss-weight:"
  "--pipeline.model.pass-semantic-gradients[(default\: False)]:pipeline.model.pass-semantic-gradients:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_semantic_nerfw_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_semantic_nerfw_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_semantic_nerfw_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_semantic_nerfw_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_semantic_nerfw_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_tensorf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: tensorf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.init-resolution[initial render resolution (default\: 128)]:pipeline.model.init-resolution:"
  "--pipeline.model.final-resolution[final render resolution (default\: 300)]:pipeline.model.final-resolution:"
  "--pipeline.model.upsampling-iters[specifies a list of iteration step numbers to perform upsampling (default\: 2000 3000 4000 5500 7000)]:pipeline.model.upsampling-iters:"
  "--pipeline.model.num-samples[Number of samples in field evaluation (default\: 50)]:pipeline.model.num-samples:"
  "--pipeline.model.num-uniform-samples[Number of samples in density evaluation (default\: 200)]:pipeline.model.num-uniform-samples:"
  "--pipeline.model.num-den-components[Number of components in density encoding (default\: 16)]:pipeline.model.num-den-components:"
  "--pipeline.model.num-color-components[Number of components in color encoding (default\: 48)]:pipeline.model.num-color-components:"
  "--pipeline.model.appearance-dim[Number of channels for color encoding (default\: 27)]:pipeline.model.appearance-dim:"
  "--pipeline.model.tensorf-encoding[(default\: vm)]:pipeline.model.tensorf-encoding:(triplane vm cp)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.001)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(linear cosine)"
  "--optimizers.encodings.optimizer.lr[The learning rate to use. (default\: 0.02)]:optimizers.encodings.optimizer.lr:"
  "--optimizers.encodings.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.encodings.optimizer.eps:"
  "--optimizers.encodings.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.encodings.optimizer.max-norm:"
  "--optimizers.encodings.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.encodings.optimizer.weight-decay:"
  "--optimizers.encodings.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.encodings.scheduler.lr-pre-warmup:"
  "--optimizers.encodings.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.002)]:optimizers.encodings.scheduler.lr-final:"
  "--optimizers.encodings.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.encodings.scheduler.warmup-steps:"
  "--optimizers.encodings.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.encodings.scheduler.max-steps:"
  "--optimizers.encodings.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.encodings.scheduler.ramp:(linear cosine)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_tensorf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_tensorf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_tensorf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_tensorf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_tensorf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_tensorf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_tensorf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_tensorf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_tensorf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_tensorf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_vanilla_nerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: vanilla-nerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 64)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: False)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--optimizers.temporal-distortion.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.temporal-distortion.optimizer.lr:"
  "--optimizers.temporal-distortion.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.temporal-distortion.optimizer.eps:"
  "--optimizers.temporal-distortion.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.temporal-distortion.optimizer.max-norm:"
  "--optimizers.temporal-distortion.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.temporal-distortion.optimizer.weight-decay:"
  "--optimizers.temporal-distortion.scheduler[(default\: None)]:optimizers.temporal-distortion.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_vanilla_nerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_vanilla_nerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_vanilla_nerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_vanilla_nerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_vanilla_nerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_volinga_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: volinga)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-gpus[total number of gpus available for train\/eval (default\: 1)]:machine.num-gpus:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(ITER_TRAIN_TIME TOTAL_TRAIN_TIME ETA TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC VIS_RAYS_PER_SEC CURR_TEST_PSNR)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(none basic pytorch)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(jpeg png)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SO3xR3 SE3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(linear cosine)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(random last_sample black white)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 32)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 32)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 32)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 24)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: True)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: True)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(piecewise uniform)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer wandb tensorboard viewer+wandb viewer+tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
)

_shtab_tyro_ns_train_volinga_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: data\/ARKitScenes\/3dod\/Validation\/41069021)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_volinga_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/blender\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_volinga_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/dnerf\/lego)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_volinga_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/iphone\/mochi-high-five)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_volinga_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: data\/ours\/posterv2)]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_volinga_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \/home\/nikhil\/nerfstudio-main\/tests\/data\/lego_test\/minimal_parser)]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_volinga_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/NeRF-OSR\/Data)]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_volinga_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_volinga_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \/mnt\/local\/NuScenes)]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT FRONT_LEFT FRONT_RIGHT BACK BACK_LEFT BACK_RIGHT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_volinga_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/phototourism\/brandenburg-gate)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(pca up vertical none)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_volinga_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: data\/scannet\/scene0423_02)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses focus none)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_volinga_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/DTU\/scan65)]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_volinga_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: data\/sitcoms3d\/TBBT-big_living_room)]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)


_shtab_tyro_ns_train() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_options+=(': :_shtab_tyro_ns_train_commands' '*::: :->ns-train')
  fi
  _arguments -C $_shtab_tyro_ns_train_options

  case $state in
    ns-train)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train-$line[1]:"
      case $line[1] in
        depth-nerfacto) _shtab_tyro_ns_train_depth_nerfacto ;;
        dnerf) _shtab_tyro_ns_train_dnerf ;;
        instant-ngp) _shtab_tyro_ns_train_instant_ngp ;;
        instant-ngp-bounded) _shtab_tyro_ns_train_instant_ngp_bounded ;;
        lerf) _shtab_tyro_ns_train_lerf ;;
        lerf-big) _shtab_tyro_ns_train_lerf_big ;;
        lerf-lite) _shtab_tyro_ns_train_lerf_lite ;;
        mipnerf) _shtab_tyro_ns_train_mipnerf ;;
        nerfacto) _shtab_tyro_ns_train_nerfacto ;;
        nerfacto-big) _shtab_tyro_ns_train_nerfacto_big ;;
        nerfplayer-nerfacto) _shtab_tyro_ns_train_nerfplayer_nerfacto ;;
        nerfplayer-ngp) _shtab_tyro_ns_train_nerfplayer_ngp ;;
        neus) _shtab_tyro_ns_train_neus ;;
        neus-facto) _shtab_tyro_ns_train_neus_facto ;;
        phototourism) _shtab_tyro_ns_train_phototourism ;;
        semantic-nerfw) _shtab_tyro_ns_train_semantic_nerfw ;;
        tensorf) _shtab_tyro_ns_train_tensorf ;;
        vanilla-nerf) _shtab_tyro_ns_train_vanilla_nerf ;;
        volinga) _shtab_tyro_ns_train_volinga ;;
      esac
  esac
}

_shtab_tyro_ns_train_depth_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_depth_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_depth_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_depth_nerfacto_options+=(': :_shtab_tyro_ns_train_depth_nerfacto_commands' '*::: :->depth-nerfacto')
  fi
  _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_options

  case $state in
    depth-nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_depth_nerfacto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_depth_nerfacto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_dnerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_dnerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_dnerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_dnerf_options+=(': :_shtab_tyro_ns_train_dnerf_commands' '*::: :->dnerf')
  fi
  _arguments -C $_shtab_tyro_ns_train_dnerf_options

  case $state in
    dnerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_dnerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_dnerf_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_dnerf_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_dnerf_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_dnerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_dnerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_dnerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_dnerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_dnerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_dnerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_dnerf_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_dnerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_dnerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_dnerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_instant_ngp() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_instant_ngp_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_instant_ngp_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_instant_ngp_options+=(': :_shtab_tyro_ns_train_instant_ngp_commands' '*::: :->instant-ngp')
  fi
  _arguments -C $_shtab_tyro_ns_train_instant_ngp_options

  case $state in
    instant-ngp)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_instant_ngp-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_instant_ngp_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_instant_ngp_bounded() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_instant_ngp_bounded_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_instant_ngp_bounded_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_instant_ngp_bounded_options+=(': :_shtab_tyro_ns_train_instant_ngp_bounded_commands' '*::: :->instant-ngp-bounded')
  fi
  _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_options

  case $state in
    instant-ngp-bounded)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_instant_ngp_bounded-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_instant_ngp_bounded_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_options+=(': :_shtab_tyro_ns_train_lerf_commands' '*::: :->lerf')
  fi
  _arguments -C $_shtab_tyro_ns_train_lerf_options

  case $state in
    lerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_lerf_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_lerf_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_lerf_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_lerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_lerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_lerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_lerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_lerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_lerf_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_lerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_lerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf_big() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_big_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_big_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_big_options+=(': :_shtab_tyro_ns_train_lerf_big_commands' '*::: :->lerf-big')
  fi
  _arguments -C $_shtab_tyro_ns_train_lerf_big_options

  case $state in
    lerf-big)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf_big-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_lerf_big_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_lerf_big_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf_lite() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_lite_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_lite_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_lite_options+=(': :_shtab_tyro_ns_train_lerf_lite_commands' '*::: :->lerf-lite')
  fi
  _arguments -C $_shtab_tyro_ns_train_lerf_lite_options

  case $state in
    lerf-lite)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf_lite-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_lerf_lite_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_lerf_lite_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_mipnerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_mipnerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_mipnerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_mipnerf_options+=(': :_shtab_tyro_ns_train_mipnerf_commands' '*::: :->mipnerf')
  fi
  _arguments -C $_shtab_tyro_ns_train_mipnerf_options

  case $state in
    mipnerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_mipnerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_mipnerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_mipnerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfacto_options+=(': :_shtab_tyro_ns_train_nerfacto_commands' '*::: :->nerfacto')
  fi
  _arguments -C $_shtab_tyro_ns_train_nerfacto_options

  case $state in
    nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfacto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_nerfacto_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfacto_big() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfacto_big_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfacto_big_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfacto_big_options+=(': :_shtab_tyro_ns_train_nerfacto_big_commands' '*::: :->nerfacto-big')
  fi
  _arguments -C $_shtab_tyro_ns_train_nerfacto_big_options

  case $state in
    nerfacto-big)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfacto_big-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_nerfacto_big_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfplayer_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfplayer_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfplayer_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfplayer_nerfacto_options+=(': :_shtab_tyro_ns_train_nerfplayer_nerfacto_commands' '*::: :->nerfplayer-nerfacto')
  fi
  _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_options

  case $state in
    nerfplayer-nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfplayer_nerfacto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_nerfacto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfplayer_ngp() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfplayer_ngp_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfplayer_ngp_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfplayer_ngp_options+=(': :_shtab_tyro_ns_train_nerfplayer_ngp_commands' '*::: :->nerfplayer-ngp')
  fi
  _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_options

  case $state in
    nerfplayer-ngp)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfplayer_ngp-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_nerfplayer_ngp_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_neus() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_neus_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_neus_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_neus_options+=(': :_shtab_tyro_ns_train_neus_commands' '*::: :->neus')
  fi
  _arguments -C $_shtab_tyro_ns_train_neus_options

  case $state in
    neus)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_neus-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_neus_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_neus_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_neus_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_neus_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_neus_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_neus_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_neus_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_neus_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_neus_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_neus_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_neus_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_neus_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_neus_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_neus_facto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_neus_facto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_neus_facto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_neus_facto_options+=(': :_shtab_tyro_ns_train_neus_facto_commands' '*::: :->neus-facto')
  fi
  _arguments -C $_shtab_tyro_ns_train_neus_facto_options

  case $state in
    neus-facto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_neus_facto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_neus_facto_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_neus_facto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_phototourism() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_phototourism_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_phototourism_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_phototourism_options+=(': :_shtab_tyro_ns_train_phototourism_commands' '*::: :->phototourism')
  fi
  _arguments -C $_shtab_tyro_ns_train_phototourism_options

  case $state in
    phototourism)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_phototourism-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_phototourism_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_phototourism_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_phototourism_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_phototourism_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_phototourism_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_phototourism_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_phototourism_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_phototourism_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_phototourism_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_phototourism_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_phototourism_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_phototourism_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_phototourism_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_semantic_nerfw() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_semantic_nerfw_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_semantic_nerfw_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_semantic_nerfw_options+=(': :_shtab_tyro_ns_train_semantic_nerfw_commands' '*::: :->semantic-nerfw')
  fi
  _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_options

  case $state in
    semantic-nerfw)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_semantic_nerfw-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_semantic_nerfw_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_tensorf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_tensorf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_tensorf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_tensorf_options+=(': :_shtab_tyro_ns_train_tensorf_commands' '*::: :->tensorf')
  fi
  _arguments -C $_shtab_tyro_ns_train_tensorf_options

  case $state in
    tensorf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_tensorf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_tensorf_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_tensorf_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_tensorf_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_tensorf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_tensorf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_tensorf_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_tensorf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_tensorf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_tensorf_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_tensorf_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_tensorf_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_tensorf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_tensorf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_vanilla_nerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_vanilla_nerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_vanilla_nerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_vanilla_nerf_options+=(': :_shtab_tyro_ns_train_vanilla_nerf_commands' '*::: :->vanilla-nerf')
  fi
  _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_options

  case $state in
    vanilla-nerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_vanilla_nerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_vanilla_nerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_volinga() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_volinga_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_volinga_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_volinga_options+=(': :_shtab_tyro_ns_train_volinga_commands' '*::: :->volinga')
  fi
  _arguments -C $_shtab_tyro_ns_train_volinga_options

  case $state in
    volinga)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_volinga-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C $_shtab_tyro_ns_train_volinga_arkit_data_options ;;
        blender-data) _arguments -C $_shtab_tyro_ns_train_volinga_blender_data_options ;;
        dnerf-data) _arguments -C $_shtab_tyro_ns_train_volinga_dnerf_data_options ;;
        dycheck-data) _arguments -C $_shtab_tyro_ns_train_volinga_dycheck_data_options ;;
        instant-ngp-data) _arguments -C $_shtab_tyro_ns_train_volinga_instant_ngp_data_options ;;
        minimal-parser) _arguments -C $_shtab_tyro_ns_train_volinga_minimal_parser_options ;;
        nerfosr-data) _arguments -C $_shtab_tyro_ns_train_volinga_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C $_shtab_tyro_ns_train_volinga_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C $_shtab_tyro_ns_train_volinga_nuscenes_data_options ;;
        phototourism-data) _arguments -C $_shtab_tyro_ns_train_volinga_phototourism_data_options ;;
        scannet-data) _arguments -C $_shtab_tyro_ns_train_volinga_scannet_data_options ;;
        sdfstudio-data) _arguments -C $_shtab_tyro_ns_train_volinga_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C $_shtab_tyro_ns_train_volinga_sitcoms3d_data_options ;;
      esac
  esac
}



typeset -A opt_args
_shtab_tyro_ns_train "$@"
