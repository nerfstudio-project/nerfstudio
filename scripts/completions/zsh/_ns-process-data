#compdef ns-process-data

# AUTOMATICALLY GENERATED by `shtab`


_shtab_tyro_ns_process_data_commands() {
  local _commands=(
    "images:Process images into a nerfstudio dataset. This script does the following\:"
    "metashape:Process Metashape data into a nerfstudio dataset. This script assumes that cameras have been aligned using Metashape. After alignment, it is necessary to export the camera poses as a \`.xml\` file. This option can be found under \`File \> Export \> Export Cameras\`."
    "polycam:Process Polycam data into a nerfstudio dataset. To capture data, use the Polycam app on an iPhone or iPad with LiDAR. The capture must be in LiDAR or ROOM mode. Developer mode must be enabled in the app settings, this will enable a raw data export option in the export menus. The exported data folder is used as the input to this script."
    "realitycapture:Process RealityCapture data into a nerfstudio dataset. This script assumes that cameras have been aligned using RealityCapture. After alignment, it is necessary to export the camera poses as a \`.csv\` file using the \`Internal\/External camera parameters\` option."
    "record3d:Process Record3D data into a nerfstudio dataset. This script does the following\:"
    "video:Process videos into a nerfstudio dataset. This script does the following\:"
  )
  _describe 'ns-process-data commands' _commands
}

_shtab_tyro_ns_process_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_process_data_images_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path the data, either a video file or a directory of images. (required)]:data:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--camera-type[Camera model to use. (default\: perspective)]:camera-type:(perspective fisheye equirectangular)"
  "--matching-method[Feature matching method to use. Vocab tree is recommended for a balance of speed and accuracy. Exhaustive is slower but more accurate. Sequential is faster but should only be used for videos. (default\: vocab_tree)]:matching-method:(exhaustive sequential vocab_tree)"
  "--sfm-tool[Structure from motion tool to use. Colmap will use sift features, hloc can use many modern methods such as superpoint features and superglue matcher (default\: any)]:sfm-tool:(any colmap hloc)"
  "--refine-pixsfm[If True, runs refinement using Pixel Perfect SFM. Only works with hloc sfm_tool (sets\: refine_pixsfm\=True)]"
  "--feature-type[Type of feature to use. (default\: any)]:feature-type:(any sift superpoint superpoint_aachen superpoint_max superpoint_inloc r2d2 d2net-ss sosnet disk)"
  "--matcher-type[Matching algorithm. (default\: any)]:matcher-type:(any NN superglue superglue-fast NN-superpoint NN-ratio NN-mutual adalam)"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--skip-colmap[If True, skips COLMAP and generates transforms.json if possible. (sets\: skip_colmap\=True)]"
  "--skip-image-processing[If True, skips copying and downscaling of images and only runs COLMAP if possible and enabled (sets\: skip_image_processing\=True)]"
  "--colmap-model-path[Optionally sets the path of the colmap model. Used only when --skip-colmap is set to True. The path is relative to the output directory. (default\: colmap\/sparse\/0)]:colmap-model-path:_files"
  "--colmap-cmd[How to call the COLMAP executable. (default\: colmap)]:colmap-cmd:"
  "--images-per-equirect[Number of samples per image to take from each equirectangular image. Used only when camera-type is equirectangular. (default\: 8)]:images-per-equirect:(8 14)"
  "--crop-factor[Portion of the image to crop. All values should be in \[0,1\]. (top, bottom, left, right) (default\: 0.0 0.0 0.0 0.0)]:crop-factor:"
  "--no-gpu[If True, use GPU. (sets\: gpu\=False)]"
  "--use-sfm-depth[If True, export and use depth maps induced from SfM points. (sets\: use_sfm_depth\=True)]"
  "--include-depth-debug[If --use-sfm-depth and this flag is True, also export debug images showing SfM overlaid upon input images. (sets\: include_depth_debug\=True)]"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)

_shtab_tyro_ns_process_data_metashape_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to a folder of images. (required)]:data:_files"
  "--xml[Path to the Metashape xml file. (required)]:xml:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--max-dataset-size[Max number of images to train on. If the dataset has more, images will be sampled approximately evenly. If -1, use all images. (default\: 600)]:max-dataset-size:"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)

_shtab_tyro_ns_process_data_polycam_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path the polycam export data folder. Can be .zip file or folder. (required)]:data:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--use-uncorrected-images[If True, use the raw images from the polycam export. If False, use the corrected images. (sets\: use_uncorrected_images\=True)]"
  "--max-dataset-size[Max number of images to train on. If the dataset has more, images will be sampled approximately evenly. If -1, use all images. (default\: 600)]:max-dataset-size:"
  "--min-blur-score[Minimum blur score to use an image. If the blur score is below this value, the image will be skipped. (default\: 25)]:min-blur-score:"
  "--crop-border-pixels[Number of pixels to crop from each border of the image. Useful as borders may be black due to undistortion. (default\: 15)]:crop-border-pixels:"
  "--use-depth[If True, processes the generated depth maps from Polycam (sets\: use_depth\=True)]"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)

_shtab_tyro_ns_process_data_realitycapture_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to a folder of images. (required)]:data:_files"
  "--csv[Path to the RealityCapture cameras CSV file. (required)]:csv:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--max-dataset-size[Max number of images to train on. If the dataset has more, images will be sampled approximately evenly. If -1, use all images. (default\: 600)]:max-dataset-size:"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)

_shtab_tyro_ns_process_data_record3d_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to the record3D data. (required)]:data:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--max-dataset-size[Max number of images to train on. If the dataset has more, images will be sampled approximately evenly. If -1, use all images. (default\: 300)]:max-dataset-size:"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)

_shtab_tyro_ns_process_data_video_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path the data, either a video file or a directory of images. (required)]:data:_files"
  "--output-dir[Path to the output directory. (required)]:output-dir:_files -/"
  "--num-frames-target[Target number of frames to use for the dataset, results may not be exact. (default\: 300)]:num-frames-target:"
  "--camera-type[Camera model to use. (default\: perspective)]:camera-type:(perspective fisheye equirectangular)"
  "--matching-method[Feature matching method to use. Vocab tree is recommended for a balance of speed and accuracy. Exhaustive is slower but more accurate. Sequential is faster but should only be used for videos. (default\: vocab_tree)]:matching-method:(exhaustive sequential vocab_tree)"
  "--sfm-tool[Structure from motion tool to use. Colmap will use sift features, hloc can use many modern methods such as superpoint features and superglue matcher (default\: any)]:sfm-tool:(any colmap hloc)"
  "--feature-type[Type of feature to use. (default\: any)]:feature-type:(any sift superpoint superpoint_aachen superpoint_max superpoint_inloc r2d2 d2net-ss sosnet disk)"
  "--matcher-type[Matching algorithm. (default\: any)]:matcher-type:(any NN superglue superglue-fast NN-superpoint NN-ratio NN-mutual adalam)"
  "--num-downscales[Number of times to downscale the images. Downscales by 2 each time. For example a value of 3 will downscale the images by 2x, 4x, and 8x. (default\: 3)]:num-downscales:"
  "--skip-colmap[If True, skips COLMAP and generates transforms.json if possible. (sets\: skip_colmap\=True)]"
  "--colmap-cmd[How to call the COLMAP executable. (default\: colmap)]:colmap-cmd:"
  "--images-per-equirect[Number of samples per image to take from each equirectangular image. Used only when camera-type is equirectangular. (default\: 8)]:images-per-equirect:(8 14)"
  "--percent-radius-crop[Create circle crop mask. The radius is the percent of the image diagonal. (default\: 1.0)]:percent-radius-crop:"
  "--crop-factor[Portion of the image to crop. All values should be in \[0,1\]. (top, bottom, left, right) (default\: 0.0 0.0 0.0 0.0)]:crop-factor:"
  "--use-sfm-depth[If True, export and use depth maps induced from SfM points. (sets\: use_sfm_depth\=True)]"
  "--include-depth-debug[If --use-sfm-depth and this flag is True, also export debug images showing SfM overlaid upon input images. (sets\: include_depth_debug\=True)]"
  "--no-gpu[If True, use GPU. (sets\: gpu\=False)]"
  "--verbose[If True, print extra logging. (sets\: verbose\=True)]"
)


_shtab_tyro_ns_process_data() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_process_data_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_process_data_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_process_data_options+=(': :_shtab_tyro_ns_process_data_commands' '*::: :->ns-process-data')
  fi
  _arguments -C $_shtab_tyro_ns_process_data_options

  case $state in
    ns-process-data)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_process_data-$line[1]:"
      case $line[1] in
        images) _arguments -C $_shtab_tyro_ns_process_data_images_options ;;
        metashape) _arguments -C $_shtab_tyro_ns_process_data_metashape_options ;;
        polycam) _arguments -C $_shtab_tyro_ns_process_data_polycam_options ;;
        realitycapture) _arguments -C $_shtab_tyro_ns_process_data_realitycapture_options ;;
        record3d) _arguments -C $_shtab_tyro_ns_process_data_record3d_options ;;
        video) _arguments -C $_shtab_tyro_ns_process_data_video_options ;;
      esac
  esac
}



typeset -A opt_args
_shtab_tyro_ns_process_data "$@"
