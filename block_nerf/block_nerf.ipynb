{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(array: np.ndarray):\n",
    "    print(np.array2string(array, separator=\", \", formatter={\"float_kind\": lambda x: \"%.4f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transforms(path: Path, splits: int):\n",
    "    transforms = load_json(path)\n",
    "    frames = transforms[\"frames\"]\n",
    "    split_frames = np.array_split(frames, splits)\n",
    "    \n",
    "    split_indexes = []\n",
    "    split_transforms = []\n",
    "    for split in split_frames:\n",
    "        split_transforms.append(\n",
    "            {\n",
    "                \"camera_model\": transforms[\"camera_model\"],\n",
    "                \"fl_x\": transforms[\"fl_x\"],\n",
    "                \"fl_y\": transforms[\"fl_y\"],\n",
    "                \"cx\": transforms[\"cx\"],\n",
    "                \"cy\": transforms[\"cy\"],\n",
    "                \"w\": transforms[\"w\"],\n",
    "                \"h\": transforms[\"h\"],\n",
    "                \"k1\": transforms[\"k1\"],\n",
    "                \"k2\": transforms[\"k2\"],\n",
    "                \"p1\": transforms[\"p1\"],\n",
    "                \"p2\": transforms[\"p2\"],\n",
    "                \"frames\": split.tolist(),\n",
    "            }\n",
    "        )\n",
    "        if (len(split_indexes) == 0):\n",
    "            split_indexes.append(len(split))\n",
    "        else:\n",
    "            split_indexes.append(split_indexes[-1] + len(split))\n",
    "    return split_transforms, split_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_path = Path.cwd() / \"baseline_transforms.json\"\n",
    "split_transforms, split_indexes = split_transforms(transforms_path, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[275, 550, 824, 1098]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the split transforms by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the original, non-scaled and non-centered transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataparser_transforms to scale and rotate the transforms\n",
    "dataparser_transforms_path = Path.cwd() / \"dataparser_transforms.json\"\n",
    "dataparser_transforms = load_json(dataparser_transforms_path)\n",
    "\n",
    "dp_t = np.array(dataparser_transforms[\"transform\"])\n",
    "dp_scale = dataparser_transforms[\"scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0000, -1.0000, -0.0000, -3.4461],\n",
      " [0.9848, -0.0000, 0.1736, 106.3866],\n",
      " [-0.1736, -0.0000, 0.9848, -2.3626],\n",
      " [0.0000, 0.0000, 0.0000, 1.0000]]\n"
     ]
    }
   ],
   "source": [
    "# Use the dp_t and dp_scale to scale and rotate the camera_to_world matrices in the camera_path file such that they're comparable to the split_transforms\n",
    "\n",
    "transforms_matrix = np.array(split_transforms[0][\"frames\"][0][\"transform_matrix\"])\n",
    "pretty_print(transforms_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0387, 0.0485, 0.9981, 0.4484],\n",
      " [0.9993, -0.0019, -0.0387, 0.9853],\n",
      " [-0.0000, 0.9988, -0.0485, -0.0018],\n",
      " [0.0000, 0.0000, 0.0000, 1.0000]]\n"
     ]
    }
   ],
   "source": [
    "camera_path_path = Path.cwd() / \"camera_path_one_lap.json\"\n",
    "camera_path = load_json(camera_path_path)\n",
    "camera_path_c2w = np.array(camera_path[\"camera_path\"][0][\"camera_to_world\"]).reshape(4,4,)\n",
    "pretty_print(camera_path_c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0002, 0.9988, -0.0485, 0.2364],\n",
      " [0.9992, -0.0017, -0.0388, -0.3360],\n",
      " [-0.0389, -0.0485, -0.9981, -0.0437],\n",
      " [0.0000, 0.0000, 0.0000, 1.0000]]\n"
     ]
    }
   ],
   "source": [
    "a = dp_t @ camera_path_c2w\n",
    "a[:3, 3] *= dp_scale\n",
    "a = np.vstack((a, [0, 0, 0, 1]))\n",
    "\n",
    "pretty_print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.81123024696991"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distance between the two matrices trasform_matrix[:3, 3] and camera_to_world[:3, 3]\n",
    "np.linalg.norm(transforms_matrix[:3, 3] - a[:3, 3])\n",
    "# transforms_matrix[:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0387, 0.9993, -0.0000, 0.0000],\n",
      " [0.0485, -0.0019, 0.9988, 0.0000],\n",
      " [0.9981, -0.0387, -0.0485, 0.0000],\n",
      " [0.4484, 0.9853, -0.0018, 1.0000]]\n"
     ]
    }
   ],
   "source": [
    "b = [0.03871940596928383,0.9992501550311972,-2.220446121113367e-16,0,0.04846804299786681,-0.0018780620887794875,0.9988229486229716,0,0.9980739592677991,-0.03867383019325542,-0.04850441561635006,0,0.4483894695235361,0.985300560475246,-0.0018124304538501418,1]\n",
    "b = np.array(b).reshape(4,4,)\n",
    "pretty_print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
