{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Pipelines\n",
    "\n",
    "Here we explain how to create custom pipelines in nerfactory. Pipelines are composed of two components, namely a Dataloader and a Model. We'll show how to make an incremental dataloader with scene conditioning.\n",
    "\n",
    "#TODO(ethan): show a figure depicting the different modules that go into a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# HIDDEN\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, Optional, Tuple\n",
    "import torch\n",
    "\n",
    "from nerfactory.utils.config import VanillaDataloaderConfig, ModelConfig, PipelineConfig, ViewerConfig\n",
    "\n",
    "from nerfactory.dataloaders.base import Dataloader\n",
    "from nerfactory.models.base import Model\n",
    "from nerfactory.pipelines.base import Pipeline\n",
    "\n",
    "from nerfactory.models.instant_ngp import NGPModel\n",
    "from nerfactory.cameras.rays import RayBundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RayBundle class\n",
    "\n",
    "In the RayBundle class, we allow uses to add non-default attributes for conditioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalDataloaderConfig(VanillaDataloaderConfig):\n",
    "    _target = IncrementalDataloaderConfig\n",
    "    add_cameras_per_iter: int = 10\n",
    "    num_cameras_to_add: int = 1\n",
    "\n",
    "class IncrementalDataloader(Dataloader): # no longer nn.Module\n",
    "    \"\"\"A SLAM-based dataloader.\"\"\"\n",
    "\n",
    "    config: IncrementalDataloaderConfig\n",
    "\n",
    "    def populate_train_modules(self):\n",
    "        \"\"\"Populate the train dataloader modules.\"\"\"\n",
    "        # self.train_image_dataset = ImageDataset # torch dataloader\n",
    "        # self.train_image_sampler = CacheImageSampler\n",
    "        # self.train_pixel_sampler = PixelSampler\n",
    "        # ... \n",
    "        # self.train_ray_generator = RayGenerator # nn.Module\n",
    "\n",
    "    def populate_eval_modules(self):\n",
    "        \"\"\"Populate the eval dataloader modules.\"\"\"\n",
    "        # self.eval_image_dataset = ImageDataset\n",
    "        # self.eval_dataloader = FixedIndicesEvalDataloader\n",
    "\n",
    "    def next_train(self, step: int) -> Tuple[RayBundle, Dict]:\n",
    "        \"\"\"Get the next batch of training data by stringing together the train modules.\"\"\"\n",
    "        if step % self.config.add_cameras_per_iter == 0:\n",
    "            print(\"do something here\")\n",
    "        ray_bundle = RayBundle()\n",
    "        ray_bundle.metadata[\"scene_indices\"] = None # TODO(ethan): populate this with a tensor of scene indices\n",
    "        dict_ = {}\n",
    "        return ray_bundle, dict_\n",
    "\n",
    "    def next_eval(self, step: int) -> Tuple[RayBundle, Dict]:\n",
    "        \"\"\"Get the next batch of eval data by stringing together the eval modules.\"\"\"\n",
    "        ray_bundle = RayBundle()\n",
    "        ray_bundle.metadata[\"scene_indices\"] = None\n",
    "        dict_ = {}\n",
    "        return ray_bundle, dict_\n",
    "\n",
    "\n",
    "class SceneConditionNGPModelConfig(ModelConfig):\n",
    "    _target =  SceneConditionNGPModel\n",
    "    coarse_field: str = \"temp\"\n",
    "    fine_field: str = \"temp2\"\n",
    "\n",
    "class SceneConditionNGPModel(Model):\n",
    "    \"\"\"An instant ngp model modified slightly to output semantics.\"\"\"\n",
    "\n",
    "    config: SceneConditionNGPModelConfig\n",
    "\n",
    "    def populate_modules(self):\n",
    "        self.ngp_model = NGPModel(coarse_field=self.config.coarse_field, fine_field=self.config.fine_field)\n",
    "\n",
    "    def get_outputs(self, ray_bundle: RayBundle) -> Dict[str, torch.Tensor]:\n",
    "        # TODO(ethan): pass in batch from the forward function\n",
    "        # TODO(ethan): rename batch to something else\n",
    "        outputs = self.ngp_model.forward(ray_bundle)\n",
    "        outputs[\"semantics\"] = torch.rand_like(outputs[\"rgb\"])\n",
    "        return outputs\n",
    "\n",
    "    def get_loss_dict(self):\n",
    "        return {}\n",
    "\n",
    "class CustomPipeline(Pipeline):\n",
    "    \"\"\"The Instant NGP pipeline.\"\"\"\n",
    "\n",
    "    config: PipelineConfig\n",
    "\n",
    "    def train_step(self, step: int):\n",
    "        ray_bundle, batch = self.dataloader.next_train(step=step)\n",
    "        # TODO: maybe run a CNN on the data before passing into model\n",
    "        model_outputs, loss_dict, metrics_dict = self.model(ray_bundle, batch)\n",
    "        # TODO: update pixel sampler state with loss map to show the flexibilty of our Pipeline\n",
    "        return model_outputs, loss_dict, metrics_dict\n",
    "\n",
    "    def eval_step(self):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader()\n",
    "model = SceneConditionNGPModel()\n",
    "pipeline = CustomPipeline.from_dataloader_and_model(dataloader=dataloader, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipelines from a config\n",
    "\n",
    "Now we show how to create a pipeline from a config, which has the following form:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Configuration for pipeline instantiation\"\"\"\n",
    "\n",
    "    _target_: str = MISSING\n",
    "    dataloader_config: DataloaderConfig = MISSING\n",
    "    graph_config: GraphConfig = MISSING\n",
    "```\n",
    "\n",
    "See [nerfactory/utils/config.py](nerfactory/utils/config.py) for more details. In this example, we will simply load from an existing configuration from [configs/graph_instant_ngp.yaml](configs/graph_instant_ngp.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import hydra\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "from hydra import compose, initialize\n",
    "\n",
    "initialize(version_base=\"1.2\", config_path=\"../configs/\")\n",
    "config_name = \"graph_instant_ngp.yaml\"\n",
    "config = compose(config_name)\n",
    "pipeline_config = config.pipeline\n",
    "pprint.pprint(pipeline_config)\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "from nerfactory.pipelines.base import setup_pipeline\n",
    "\n",
    "pipeline = setup_pipeline(pipeline_config, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_train_loss_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nerfactory')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e691f033e0f2f1b9c0a11e7e81375a1e27aec87a71fd1b1eaa545f7a5e61b3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
