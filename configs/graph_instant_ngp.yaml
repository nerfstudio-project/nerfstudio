defaults:
  - graph_default
  - _self_

method_name: instant_ngp

viewer:
  enable: true
  num_rays_per_chunk: 16384

pipeline:
  dataloader:
    train_dataset:
      _target_: nerfactory.dataloaders.datasets.Blender
      data_directory: data/blender/lego
      alpha_color: white
      downscale_factor: 1
    train_num_rays_per_batch: 8192
    eval_dataset:
      _target_: nerfactory.dataloaders.datasets.Blender
      data_directory: data/blender/lego
      alpha_color: white
      downscale_factor: 1
    eval_num_rays_per_chunk: 8192
  model:
    _target_: nerfactory.models.instant_ngp.NGPModel
    enable_density_field: true
    enable_collider: false
    field_implementation: tcnn # torch, tcnn, ...
    loss_coefficients: # loss coefficients
      rgb_loss: 1.0

    density_field_config:
      # Please see the docstr for DensityGrid on how to set those arguments.
      _target_: nerfactory.fields.density_fields.density_grid.DensityGrid
      center: 0.0 # simply set it as the center of the scene bbox
      base_scale: 3.0 # simply set it as the scale of the scene bbox
      num_cascades: 1 # if using more than 1 cascade, the `base_scale` can be smaller than scene scale.
      resolution: 128
      update_every_num_iters: 16

# optimizer options for network
optimizers:
  fields:
    optimizer:
      lr: 3e-3
      eps: 1e-15 # NGP prefers small eps
    # Note: If you want slightly faster coverange, you can use the following optimizer instead, which
    # requires to install apex following https://github.com/NVIDIA/apex#linux
    # optimizer:
    #   _target_: apex.optimizers.FusedAdam
    #   lr: 3e-3
    #   eps: 1e-15
    scheduler: null

trainer:
  mixed_precision: true # Stabilizes training when using tcnn
